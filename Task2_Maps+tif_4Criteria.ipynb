{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1bc47d5-bc61-4acd-aad2-21ff04e3573a",
   "metadata": {},
   "source": [
    "BENV0093 TBPS6 - Wind Speed Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62ea462f-a50a-4890-83fd-3232227d8335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "WIND SPEED DATA PROCESSING\n",
      "================================================================================\n",
      "Extrapolation factor: 1.3900\n",
      "\n",
      "Step 1: Loading wind speed data\n",
      "<xarray.Dataset> Size: 987kB\n",
      "Dimensions:      (y: 235, x: 131, season: 4)\n",
      "Coordinates:\n",
      "  * y            (y) int32 940B 12500 17500 22500 ... 1172500 1177500 1182500\n",
      "  * x            (x) int32 524B 2500 7500 12500 17500 ... 642500 647500 652500\n",
      "  * season       (season) object 32B 'spring' 'summer' 'autumn' 'winter'\n",
      "Data variables:\n",
      "    wind_speed   (season, y, x) float64 985kB ...\n",
      "    spatial_ref  int32 4B ...\n",
      "Found variable: 'wind_speed'\n",
      "Averaged over 'season' dimension\n",
      "Shape: (235, 131)\n",
      "Range: 2.73 - 7.50 m/s\n",
      "Mean: 4.26 m/s\n",
      "\n",
      "Step 2: Extrapolating to 100m\n",
      "Formula: U_100 = U_10 * 1.3900\n",
      "Range: 3.80 - 10.42 m/s\n",
      "Mean: 5.92 m/s\n",
      "\n",
      "Step 3: Calculating suitability scores\n",
      "v < 6.0: 6,689 cells\n",
      "6.0 <= v <= 9.0: 3,636 cells\n",
      "v > 9.0: 72 cells\n",
      "Score mean: 1.13\n",
      "\n",
      "Step 4: Setting up GeoTIFF parameters\n",
      "Flipped data vertically (y coordinates increasing)\n",
      "Pixel size: 5000.00 x 5000.00 m\n",
      "\n",
      "Step 5: Saving GeoTIFF files\n",
      "Saved: D:\\BENV0093\\outputs\\wind_speed_100m_original.tif\n",
      "Saved: D:\\BENV0093\\outputs\\wind_suitability_score_original.tif\n",
      "\n",
      "Step 6: Saving reference grid\n",
      "Saved: D:\\BENV0093\\outputs\\reference_grid.pkl\n",
      "\n",
      "================================================================================\n",
      "PROCESSING COMPLETE\n",
      "================================================================================\n",
      "Resolution: 235 x 131\n",
      "Valid data: 10,397 cells\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"WIND SPEED DATA PROCESSING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Configuration\n",
    "BASE_DIR = Path('D:/BENV0093')\n",
    "DATASET_DIR = BASE_DIR / 'Dateset_T2'\n",
    "OUTPUT_DIR = BASE_DIR / 'outputs'\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "WIND_SPEED_NC = DATASET_DIR / 'WindSpeed' / 'wind_speed.nc'\n",
    "UK_BOUNDARY_SHP = BASE_DIR / 'UK_ITL1_Boundaries.shp'\n",
    "WIND_100M_TIF = OUTPUT_DIR / 'wind_speed_100m_original.tif'\n",
    "WIND_SCORE_TIF = OUTPUT_DIR / 'wind_suitability_score_original.tif'\n",
    "REFERENCE_GRID_PKL = OUTPUT_DIR / 'reference_grid.pkl'\n",
    "\n",
    "DATA_HEIGHT = 10\n",
    "TURBINE_HEIGHT = 100\n",
    "HELLMAN_EXPONENT = 0.143\n",
    "WIND_EXTRAPOLATION_FACTOR = (TURBINE_HEIGHT / DATA_HEIGHT) ** HELLMAN_EXPONENT\n",
    "\n",
    "WIND_THRESHOLD_MIN = 6.0\n",
    "WIND_THRESHOLD_MAX = 9.0\n",
    "MAX_SCORE = 10.0\n",
    "SCORE_SLOPE = MAX_SCORE / (WIND_THRESHOLD_MAX - WIND_THRESHOLD_MIN)\n",
    "\n",
    "NODATA_VALUE = -9999\n",
    "CRS_EPSG = 27700\n",
    "\n",
    "print(f\"Extrapolation factor: {WIND_EXTRAPOLATION_FACTOR:.4f}\")\n",
    "\n",
    "if not WIND_SPEED_NC.exists():\n",
    "    print(f\"ERROR: Wind speed file not found: {WIND_SPEED_NC}\")\n",
    "    exit(1)\n",
    "\n",
    "# Step 1: Load data\n",
    "print(\"\\nStep 1: Loading wind speed data\")\n",
    "ds = xr.open_dataset(WIND_SPEED_NC)\n",
    "print(ds)\n",
    "\n",
    "wind_var_names = ['wind_speed', 'ws', 'u10', 'wind', 'speed', 'Band1']\n",
    "wind_10m = None\n",
    "for var_name in wind_var_names:\n",
    "    if var_name in ds.data_vars or var_name in ds:\n",
    "        wind_10m = ds[var_name]\n",
    "        print(f\"Found variable: '{var_name}'\")\n",
    "        break\n",
    "\n",
    "if wind_10m is None:\n",
    "    print(f\"ERROR: Wind speed variable not found\")\n",
    "    print(f\"Available: {list(ds.data_vars.keys())}\")\n",
    "    exit(1)\n",
    "\n",
    "if wind_10m.ndim == 3:\n",
    "    # Try to find the time/season dimension\n",
    "    possible_time_dims = ['time', 'season', 't']\n",
    "    time_dim = None\n",
    "    for dim in possible_time_dims:\n",
    "        if dim in wind_10m.dims:\n",
    "            time_dim = dim\n",
    "            break\n",
    "    \n",
    "    if time_dim:\n",
    "        wind_10m_array = wind_10m.mean(dim=time_dim).values\n",
    "        print(f\"Averaged over '{time_dim}' dimension\")\n",
    "    else:\n",
    "        print(f\"ERROR: Could not find time/season dimension\")\n",
    "        print(f\"Available dimensions: {wind_10m.dims}\")\n",
    "        exit(1)\n",
    "elif wind_10m.ndim == 2:\n",
    "    wind_10m_array = wind_10m.values\n",
    "else:\n",
    "    print(f\"ERROR: Unexpected dimensions: {wind_10m.ndim}\")\n",
    "    exit(1)\n",
    "\n",
    "if 'x' in ds.coords and 'y' in ds.coords:\n",
    "    x_coords = ds['x'].values\n",
    "    y_coords = ds['y'].values\n",
    "elif 'lon' in ds.coords and 'lat' in ds.coords:\n",
    "    x_coords = ds['lon'].values\n",
    "    y_coords = ds['lat'].values\n",
    "else:\n",
    "    print(\"ERROR: Coordinates not found\")\n",
    "    exit(1)\n",
    "\n",
    "print(f\"Shape: {wind_10m_array.shape}\")\n",
    "print(f\"Range: {np.nanmin(wind_10m_array):.2f} - {np.nanmax(wind_10m_array):.2f} m/s\")\n",
    "print(f\"Mean: {np.nanmean(wind_10m_array):.2f} m/s\")\n",
    "\n",
    "# Step 2: Extrapolate to 100m\n",
    "print(f\"\\nStep 2: Extrapolating to {TURBINE_HEIGHT}m\")\n",
    "wind_100m_array = wind_10m_array * WIND_EXTRAPOLATION_FACTOR\n",
    "print(f\"Formula: U_100 = U_10 * {WIND_EXTRAPOLATION_FACTOR:.4f}\")\n",
    "print(f\"Range: {np.nanmin(wind_100m_array):.2f} - {np.nanmax(wind_100m_array):.2f} m/s\")\n",
    "print(f\"Mean: {np.nanmean(wind_100m_array):.2f} m/s\")\n",
    "\n",
    "# Step 3: Calculate suitability scores\n",
    "print(\"\\nStep 3: Calculating suitability scores\")\n",
    "wind_score_array = np.full_like(wind_100m_array, np.nan, dtype=np.float32)\n",
    "valid_mask = ~np.isnan(wind_100m_array)\n",
    "\n",
    "mask_low = valid_mask & (wind_100m_array < WIND_THRESHOLD_MIN)\n",
    "wind_score_array[mask_low] = 0.0\n",
    "\n",
    "mask_medium = valid_mask & (wind_100m_array >= WIND_THRESHOLD_MIN) & (wind_100m_array <= WIND_THRESHOLD_MAX)\n",
    "wind_score_array[mask_medium] = SCORE_SLOPE * (wind_100m_array[mask_medium] - WIND_THRESHOLD_MIN)\n",
    "\n",
    "mask_high = valid_mask & (wind_100m_array > WIND_THRESHOLD_MAX)\n",
    "wind_score_array[mask_high] = MAX_SCORE\n",
    "\n",
    "print(f\"v < {WIND_THRESHOLD_MIN}: {mask_low.sum():,} cells\")\n",
    "print(f\"{WIND_THRESHOLD_MIN} <= v <= {WIND_THRESHOLD_MAX}: {mask_medium.sum():,} cells\")\n",
    "print(f\"v > {WIND_THRESHOLD_MAX}: {mask_high.sum():,} cells\")\n",
    "\n",
    "valid_scores = wind_score_array[~np.isnan(wind_score_array)]\n",
    "print(f\"Score mean: {valid_scores.mean():.2f}\")\n",
    "\n",
    "# Step 4: Setup GeoTIFF parameters\n",
    "print(\"\\nStep 4: Setting up GeoTIFF parameters\")\n",
    "rows, cols = wind_100m_array.shape\n",
    "x_spacing = abs(x_coords[1] - x_coords[0]) if len(x_coords) > 1 else 1000\n",
    "y_spacing = abs(y_coords[1] - y_coords[0]) if len(y_coords) > 1 else 1000\n",
    "\n",
    "# Check if y coordinates are increasing or decreasing\n",
    "if y_coords[1] > y_coords[0]:\n",
    "    # Y increases (bottom to top) - need to flip data\n",
    "    wind_100m_array = np.flipud(wind_100m_array)\n",
    "    wind_score_array = np.flipud(wind_score_array)\n",
    "    print(\"Flipped data vertically (y coordinates increasing)\")\n",
    "\n",
    "x_min = x_coords.min() - x_spacing / 2\n",
    "y_max = y_coords.max() + y_spacing / 2\n",
    "transform = from_origin(x_min, y_max, x_spacing, y_spacing)\n",
    "extent = [x_min, x_min + cols * x_spacing, y_max - rows * y_spacing, y_max]\n",
    "print(f\"Pixel size: {x_spacing:.2f} x {y_spacing:.2f} m\")\n",
    "\n",
    "# Step 5: Save GeoTIFF files\n",
    "print(\"\\nStep 5: Saving GeoTIFF files\")\n",
    "wind_100m_save = np.where(np.isnan(wind_100m_array), NODATA_VALUE, wind_100m_array)\n",
    "wind_score_save = np.where(np.isnan(wind_score_array), NODATA_VALUE, wind_score_array)\n",
    "\n",
    "metadata = {\n",
    "    'driver': 'GTiff',\n",
    "    'dtype': 'float32',\n",
    "    'nodata': NODATA_VALUE,\n",
    "    'width': cols,\n",
    "    'height': rows,\n",
    "    'count': 1,\n",
    "    'crs': f'EPSG:{CRS_EPSG}',\n",
    "    'transform': transform,\n",
    "    'compress': 'lzw'\n",
    "}\n",
    "\n",
    "with rasterio.open(WIND_100M_TIF, 'w', **metadata) as dst:\n",
    "    dst.write(wind_100m_save.astype('float32'), 1)\n",
    "print(f\"Saved: {WIND_100M_TIF}\")\n",
    "\n",
    "with rasterio.open(WIND_SCORE_TIF, 'w', **metadata) as dst:\n",
    "    dst.write(wind_score_save.astype('float32'), 1)\n",
    "print(f\"Saved: {WIND_SCORE_TIF}\")\n",
    "\n",
    "# Step 6: Save reference grid\n",
    "print(\"\\nStep 6: Saving reference grid\")\n",
    "reference_data = {\n",
    "    'extent': extent,\n",
    "    'transform': transform,\n",
    "    'rows': rows,\n",
    "    'cols': cols,\n",
    "    'shape': (rows, cols),\n",
    "    'pixel_size': (x_spacing, y_spacing),\n",
    "    'crs': CRS_EPSG,\n",
    "    'x_spacing': x_spacing,\n",
    "    'y_spacing': y_spacing,\n",
    "    'x_min': x_min,\n",
    "    'y_max': y_max,\n",
    "}\n",
    "\n",
    "with open(REFERENCE_GRID_PKL, 'wb') as f:\n",
    "    pickle.dump(reference_data, f)\n",
    "print(f\"Saved: {REFERENCE_GRID_PKL}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PROCESSING COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Resolution: {rows} x {cols}\")\n",
    "print(f\"Valid data: {(~np.isnan(wind_100m_array)).sum():,} cells\")\n",
    "\n",
    "ds.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c72bc60-d88f-4e0f-a1eb-a3577ab3b5b7",
   "metadata": {},
   "source": [
    "Wind Speed Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41b7f130-ba73-4184-86ac-76cde27ca442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "WIND SPEED VISUALIZATION\n",
      "================================================================================\n",
      "\n",
      "Loading data\n",
      "Data shape: (235, 131)\n",
      "Valid wind cells: 10,397\n",
      "Valid score cells: 10,397\n",
      "\n",
      "================================================================================\n",
      "GENERATING MAP 1: WIND SPEED\n",
      "================================================================================\n",
      "Saved: D:\\BENV0093\\outputs\\maps\\map1_wind_speed_100m_enhanced.png\n",
      "\n",
      "================================================================================\n",
      "GENERATING MAP 2: SUITABILITY SCORE\n",
      "================================================================================\n",
      "Saved: D:\\BENV0093\\outputs\\maps\\map2_wind_suitability_score_enhanced.png\n",
      "\n",
      "================================================================================\n",
      "VISUALIZATION COMPLETE\n",
      "================================================================================\n",
      "Output files:\n",
      "  D:\\BENV0093\\outputs\\maps\\map1_wind_speed_100m_enhanced.png\n",
      "  D:\\BENV0093\\outputs\\maps\\map2_wind_suitability_score_enhanced.png\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap, BoundaryNorm\n",
    "import matplotlib.patches as mpatches\n",
    "import geopandas as gpd\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"WIND SPEED VISUALIZATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Configuration\n",
    "BASE_DIR = Path('D:/BENV0093')\n",
    "OUTPUT_DIR = BASE_DIR / 'outputs'\n",
    "MAPS_DIR = OUTPUT_DIR / 'maps'\n",
    "MAPS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "WIND_100M_TIF = OUTPUT_DIR / 'wind_speed_100m_original.tif'\n",
    "WIND_SCORE_TIF = OUTPUT_DIR / 'wind_suitability_score_original.tif'\n",
    "UK_BOUNDARY_SHP = BASE_DIR / 'UK_ITL1_Boundaries.shp'\n",
    "REFERENCE_GRID_PKL = OUTPUT_DIR / 'reference_grid.pkl'\n",
    "WIND_SPEED_MAP = MAPS_DIR / 'map1_wind_speed_100m_enhanced.png'\n",
    "WIND_SCORE_MAP = MAPS_DIR / 'map2_wind_suitability_score_enhanced.png'\n",
    "\n",
    "WIND_THRESHOLD_MIN = 6.0\n",
    "WIND_THRESHOLD_MAX = 9.0\n",
    "MAX_SCORE = 10.0\n",
    "SCORE_SLOPE = MAX_SCORE / (WIND_THRESHOLD_MAX - WIND_THRESHOLD_MIN)\n",
    "DATA_HEIGHT = 10\n",
    "TURBINE_HEIGHT = 100\n",
    "HELLMAN_EXPONENT = 0.143\n",
    "WIND_EXTRAPOLATION_FACTOR = (TURBINE_HEIGHT / DATA_HEIGHT) ** HELLMAN_EXPONENT\n",
    "NODATA_VALUE = -9999\n",
    "CRS_EPSG = 27700\n",
    "\n",
    "FIG_WIDTH = 14\n",
    "FIG_HEIGHT = 18\n",
    "DPI = 300\n",
    "OCEAN_COLOR = '#e6f2ff'\n",
    "\n",
    "WIND_COLORS = ['#313695', '#4575b4', '#74add1', '#abd9e9', '#e0f3f8',\n",
    "               '#ffffbf', '#fee090', '#fdae61', '#f46d43', '#d73027', '#a50026']\n",
    "SCORE_COLORS = ['#d73027', '#f46d43', '#fdae61', '#fee090', '#ffffbf',\n",
    "                '#d9ef8b', '#a6d96a', '#66bd63', '#1a9850', '#006837']\n",
    "\n",
    "WIND_CLASSES = {\n",
    "    'Excellent': (9.0, float('inf'), '#a50026'),\n",
    "    'Very Good': (8.0, 9.0, '#f46d43'),\n",
    "    'Good': (7.0, 8.0, '#fdae61'),\n",
    "    'Fair': (6.0, 7.0, '#fee090'),\n",
    "    'Marginal': (5.0, 6.0, '#ffffbf'),\n",
    "    'Poor': (0.0, 5.0, '#abd9e9'),\n",
    "}\n",
    "\n",
    "SCORE_CLASSES = {\n",
    "    'Excellent': (9.0, 10.01, '>=8.7 m/s', '#006837'),\n",
    "    'Good': (7.0, 9.0, '8.1-8.7 m/s', '#66bd63'),\n",
    "    'Fair': (5.0, 7.0, '7.5-8.1 m/s', '#a6d96a'),\n",
    "    'Marginal': (3.0, 5.0, '6.9-7.5 m/s', '#ffffbf'),\n",
    "    'Poor': (0.01, 3.0, '6.3-6.9 m/s', '#fdae61'),\n",
    "    'Unsuitable': (0.0, 0.01, '<6 m/s', '#d73027'),\n",
    "}\n",
    "\n",
    "# Load data\n",
    "print(\"\\nLoading data\")\n",
    "with rasterio.open(WIND_100M_TIF) as src:\n",
    "    wind_data = src.read(1)\n",
    "    transform = src.transform\n",
    "    wind_data[wind_data == NODATA_VALUE] = np.nan\n",
    "\n",
    "with rasterio.open(WIND_SCORE_TIF) as src:\n",
    "    score_data = src.read(1)\n",
    "    score_data[score_data == NODATA_VALUE] = np.nan\n",
    "\n",
    "uk_boundary = gpd.read_file(UK_BOUNDARY_SHP)\n",
    "if uk_boundary.crs.to_epsg() != CRS_EPSG:\n",
    "    uk_boundary = uk_boundary.to_crs(f'EPSG:{CRS_EPSG}')\n",
    "\n",
    "with open(REFERENCE_GRID_PKL, 'rb') as f:\n",
    "    ref = pickle.load(f)\n",
    "extent = ref['extent']\n",
    "rows = ref['rows']\n",
    "cols = ref['cols']\n",
    "\n",
    "print(f\"Data shape: {wind_data.shape}\")\n",
    "print(f\"Valid wind cells: {(~np.isnan(wind_data)).sum():,}\")\n",
    "print(f\"Valid score cells: {(~np.isnan(score_data)).sum():,}\")\n",
    "\n",
    "# Map 1: Wind Speed\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GENERATING MAP 1: WIND SPEED\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(FIG_WIDTH, FIG_HEIGHT), dpi=DPI)\n",
    "ax.set_facecolor(OCEAN_COLOR)\n",
    "ax.grid(True, alpha=0.3, linestyle='--', linewidth=0.5, color='gray', zorder=1)\n",
    "\n",
    "wind_cmap = LinearSegmentedColormap.from_list('wind_enhanced', WIND_COLORS, N=256)\n",
    "wind_levels = np.arange(3, 11, 0.5)\n",
    "wind_norm = BoundaryNorm(wind_levels, wind_cmap.N, clip=True)\n",
    "\n",
    "im = ax.imshow(wind_data, cmap=wind_cmap, norm=wind_norm,\n",
    "               extent=extent, origin='upper',\n",
    "               interpolation='bilinear', aspect='equal', zorder=2)\n",
    "\n",
    "uk_boundary.boundary.plot(ax=ax, color='black', linewidth=1.5, zorder=10)\n",
    "\n",
    "ax.set_xlabel('Easting (m)', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Northing (m)', fontsize=14, fontweight='bold')\n",
    "ax.set_title('UK Wind Speed at 100m Hub Height\\n(Extrapolated from 10m Seasonal Data)',\n",
    "             fontsize=18, fontweight='bold', pad=20)\n",
    "\n",
    "ax.ticklabel_format(style='plain')\n",
    "ax.tick_params(labelsize=11)\n",
    "\n",
    "cbar = plt.colorbar(im, ax=ax, pad=0.02, fraction=0.046, ticks=[3, 4, 5, 6, 7, 8, 9, 10])\n",
    "cbar.set_label('Wind Speed (m/s)', fontsize=13, fontweight='bold')\n",
    "cbar.ax.tick_params(labelsize=11)\n",
    "\n",
    "cbar.ax.axhline(y=WIND_THRESHOLD_MIN, color='red', linestyle='--', linewidth=2, alpha=0.7)\n",
    "cbar.ax.text(1.5, WIND_THRESHOLD_MIN, f'{WIND_THRESHOLD_MIN} m/s\\n(Threshold)', \n",
    "             fontsize=9, va='center', color='red', fontweight='bold',\n",
    "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8, edgecolor='red'))\n",
    "\n",
    "valid_wind = wind_data[~np.isnan(wind_data)]\n",
    "legend_elements = []\n",
    "for class_name, (v_min, v_max, color) in WIND_CLASSES.items():\n",
    "    if v_max == float('inf'):\n",
    "        mask = valid_wind >= v_min\n",
    "        label = f'{class_name} (>={v_min} m/s)'\n",
    "    else:\n",
    "        mask = (valid_wind >= v_min) & (valid_wind < v_max)\n",
    "        label = f'{class_name} ({v_min}-{v_max} m/s)'\n",
    "    pct = mask.sum() / len(valid_wind) * 100\n",
    "    legend_elements.append(mpatches.Patch(color=color, label=f'{label}: {pct:.1f}%'))\n",
    "\n",
    "legend = ax.legend(handles=legend_elements, loc='upper left',\n",
    "                   fontsize=10, framealpha=0.95, edgecolor='black',\n",
    "                   title='Wind Speed Classification', title_fontsize=11,\n",
    "                   fancybox=True, shadow=True)\n",
    "legend.get_frame().set_linewidth(1.5)\n",
    "\n",
    "stats_text = f\"\"\"Statistics (100m):\n",
    "Mean: {valid_wind.mean():.2f} m/s\n",
    "Min: {valid_wind.min():.2f} m/s\n",
    "Max: {valid_wind.max():.2f} m/s\n",
    "Median: {np.median(valid_wind):.2f} m/s\n",
    "Std: {valid_wind.std():.2f} m/s\n",
    "\n",
    "Viable (>={WIND_THRESHOLD_MIN} m/s):\n",
    "{(valid_wind >= WIND_THRESHOLD_MIN).sum() / len(valid_wind) * 100:.1f}%\n",
    "\n",
    "Extrapolation:\n",
    "{DATA_HEIGHT}m -> {TURBINE_HEIGHT}m (alpha={HELLMAN_EXPONENT})\n",
    "Factor: {WIND_EXTRAPOLATION_FACTOR:.3f}x\n",
    "\n",
    "Grid: {rows}x{cols}\n",
    "Coverage: {len(valid_wind):,} cells\n",
    "({len(valid_wind)/(rows*cols)*100:.1f}%)\"\"\"\n",
    "\n",
    "props = dict(boxstyle='round', facecolor='white', alpha=0.95, edgecolor='black', linewidth=1.5)\n",
    "ax.text(0.02, 0.15, stats_text, transform=ax.transAxes,\n",
    "        fontsize=9, verticalalignment='bottom', horizontalalignment='left',\n",
    "        bbox=props, fontfamily='monospace')\n",
    "\n",
    "scale_x = extent[0] + (extent[1] - extent[0]) * 0.05\n",
    "scale_y = extent[2] + (extent[3] - extent[2]) * 0.05\n",
    "scale_length = 100000\n",
    "\n",
    "ax.plot([scale_x, scale_x + scale_length], [scale_y, scale_y], 'k-', linewidth=3, zorder=15)\n",
    "ax.plot([scale_x, scale_x], [scale_y - 5000, scale_y + 5000], 'k-', linewidth=3, zorder=15)\n",
    "ax.plot([scale_x + scale_length, scale_x + scale_length],\n",
    "        [scale_y - 5000, scale_y + 5000], 'k-', linewidth=3, zorder=15)\n",
    "ax.text(scale_x + scale_length/2, scale_y + 12000, '100 km',\n",
    "        ha='center', fontsize=11, fontweight='bold',\n",
    "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.9), zorder=15)\n",
    "\n",
    "arrow_x = extent[1] - (extent[1] - extent[0]) * 0.05\n",
    "arrow_y = extent[3] - (extent[3] - extent[2]) * 0.08\n",
    "ax.annotate('N', xy=(arrow_x, arrow_y + 40000), xytext=(arrow_x, arrow_y),\n",
    "            arrowprops=dict(arrowstyle='->', lw=3, color='black'),\n",
    "            fontsize=16, fontweight='bold', ha='center', zorder=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(WIND_SPEED_MAP, dpi=DPI, bbox_inches='tight', facecolor='white')\n",
    "print(f\"Saved: {WIND_SPEED_MAP}\")\n",
    "plt.close()\n",
    "\n",
    "# Map 2: Suitability Score\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GENERATING MAP 2: SUITABILITY SCORE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(FIG_WIDTH, FIG_HEIGHT), dpi=DPI)\n",
    "ax.set_facecolor(OCEAN_COLOR)\n",
    "ax.grid(True, alpha=0.3, linestyle='--', linewidth=0.5, color='gray', zorder=1)\n",
    "\n",
    "score_cmap = LinearSegmentedColormap.from_list('score_enhanced', SCORE_COLORS, N=256)\n",
    "score_levels = np.arange(0, 10.5, 0.5)\n",
    "score_norm = BoundaryNorm(score_levels, score_cmap.N, clip=True)\n",
    "\n",
    "im = ax.imshow(score_data, cmap=score_cmap, norm=score_norm,\n",
    "               extent=extent, origin='upper',\n",
    "               interpolation='bilinear', aspect='equal', zorder=2)\n",
    "\n",
    "uk_boundary.boundary.plot(ax=ax, color='black', linewidth=1.5, zorder=10)\n",
    "\n",
    "ax.set_xlabel('Easting (m)', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Northing (m)', fontsize=14, fontweight='bold')\n",
    "ax.set_title('UK Wind Speed Suitability Score (0-10)\\n(Based on 100m Hub Height Wind Speed)',\n",
    "             fontsize=18, fontweight='bold', pad=20)\n",
    "\n",
    "ax.ticklabel_format(style='plain')\n",
    "ax.tick_params(labelsize=11)\n",
    "\n",
    "cbar = plt.colorbar(im, ax=ax, pad=0.02, fraction=0.046, ticks=[0, 2, 4, 6, 8, 10])\n",
    "cbar.set_label('Suitability Score', fontsize=13, fontweight='bold')\n",
    "cbar.ax.tick_params(labelsize=11)\n",
    "\n",
    "threshold_info = [\n",
    "    (0, f'0 (v<{WIND_THRESHOLD_MIN})', '#d73027'),\n",
    "    (3.33, '3.3 (v=7)', '#fdae61'),\n",
    "    (6.67, '6.7 (v=8)', '#a6d96a'),\n",
    "    (10, f'10 (v>={WIND_THRESHOLD_MAX})', '#006837'),\n",
    "]\n",
    "\n",
    "for score, label, color in threshold_info:\n",
    "    cbar.ax.axhline(y=score, color=color, linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "    cbar.ax.text(1.3, score, label, fontsize=8, va='center',\n",
    "                 color=color, fontweight='bold',\n",
    "                 bbox=dict(boxstyle='round', facecolor='white', alpha=0.8, \n",
    "                          edgecolor=color, linewidth=1))\n",
    "\n",
    "valid_scores = score_data[~np.isnan(score_data)]\n",
    "legend_elements = []\n",
    "for class_name, (s_min, s_max, wind_range, color) in SCORE_CLASSES.items():\n",
    "    if s_max == float('inf'):\n",
    "        mask = valid_scores >= s_min\n",
    "        score_range = f'>={s_min:.0f}'\n",
    "    else:\n",
    "        mask = (valid_scores >= s_min) & (valid_scores < s_max)\n",
    "        score_range = f'{s_min:.0f}-{s_max:.0f}'\n",
    "    pct = mask.sum() / len(valid_scores) * 100\n",
    "    legend_elements.append(\n",
    "        mpatches.Patch(color=color, \n",
    "                      label=f'{class_name} ({score_range}): v {wind_range} - {pct:.1f}%'))\n",
    "\n",
    "legend = ax.legend(handles=legend_elements, loc='upper left',\n",
    "                   fontsize=10, framealpha=0.95, edgecolor='black',\n",
    "                   title='Suitability Classes', title_fontsize=11,\n",
    "                   fancybox=True, shadow=True)\n",
    "legend.get_frame().set_linewidth(1.5)\n",
    "\n",
    "score_dist = [\n",
    "    (0, 0.01, 'Zero'),\n",
    "    (0.01, 3, 'Low'),\n",
    "    (3, 6, 'Medium'),\n",
    "    (6, 9, 'High'),\n",
    "    (9, 10.01, 'V.High'),\n",
    "]\n",
    "\n",
    "dist_text = \"Distribution:\\n\"\n",
    "for s_min, s_max, label in score_dist:\n",
    "    mask = (valid_scores >= s_min) & (valid_scores < s_max)\n",
    "    pct = mask.sum() / len(valid_scores) * 100\n",
    "    dist_text += f\"{label:>7s}: {pct:5.1f}%\\n\"\n",
    "\n",
    "stats_text = f\"\"\"Statistics (Score):\n",
    "Mean: {valid_scores.mean():.2f}\n",
    "Min: {valid_scores.min():.2f}\n",
    "Max: {valid_scores.max():.2f}\n",
    "Median: {np.median(valid_scores):.2f}\n",
    "Std: {valid_scores.std():.2f}\n",
    "\n",
    "{dist_text}\n",
    "Scoring Formula:\n",
    "v<{WIND_THRESHOLD_MIN}: s=0\n",
    "{WIND_THRESHOLD_MIN}<=v<={WIND_THRESHOLD_MAX}: s={SCORE_SLOPE:.2f}(v-{WIND_THRESHOLD_MIN})\n",
    "v>{WIND_THRESHOLD_MAX}: s={MAX_SCORE}\n",
    "\n",
    "WLC Weight: 39.4%\n",
    "\n",
    "Grid: {rows}x{cols}\n",
    "Coverage: {len(valid_scores):,} cells\"\"\"\n",
    "\n",
    "props = dict(boxstyle='round', facecolor='white', alpha=0.95, edgecolor='black', linewidth=1.5)\n",
    "ax.text(0.02, 0.15, stats_text, transform=ax.transAxes,\n",
    "        fontsize=8.5, verticalalignment='bottom', horizontalalignment='left',\n",
    "        bbox=props, fontfamily='monospace')\n",
    "\n",
    "ax.plot([scale_x, scale_x + scale_length], [scale_y, scale_y], 'k-', linewidth=3, zorder=15)\n",
    "ax.plot([scale_x, scale_x], [scale_y - 5000, scale_y + 5000], 'k-', linewidth=3, zorder=15)\n",
    "ax.plot([scale_x + scale_length, scale_x + scale_length],\n",
    "        [scale_y - 5000, scale_y + 5000], 'k-', linewidth=3, zorder=15)\n",
    "ax.text(scale_x + scale_length/2, scale_y + 12000, '100 km',\n",
    "        ha='center', fontsize=11, fontweight='bold',\n",
    "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.9), zorder=15)\n",
    "\n",
    "ax.annotate('N', xy=(arrow_x, arrow_y + 40000), xytext=(arrow_x, arrow_y),\n",
    "            arrowprops=dict(arrowstyle='->', lw=3, color='black'),\n",
    "            fontsize=16, fontweight='bold', ha='center', zorder=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(WIND_SCORE_MAP, dpi=DPI, bbox_inches='tight', facecolor='white')\n",
    "print(f\"Saved: {WIND_SCORE_MAP}\")\n",
    "plt.close()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VISUALIZATION COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Output files:\")\n",
    "print(f\"  {WIND_SPEED_MAP}\")\n",
    "print(f\"  {WIND_SCORE_MAP}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cad1c26-8742-4888-95bf-f5443d6e02bf",
   "metadata": {},
   "source": [
    "Grid Distance Processing\n",
    "Calculates distance to high-voltage transmission lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50d6c48e-67cc-4bdd-8b13-8e79f3c866ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "GRID DISTANCE PROCESSING (PRECISE VECTOR METHOD)\n",
      "With EXPONENTIAL DECAY SCORING (λ=7.21)\n",
      "================================================================================\n",
      "\n",
      "Step 1: Loading reference grid\n",
      "Shape: 235 x 131\n",
      "Pixel size: 5000.00 x 5000.00 m\n",
      "Extent: X[0, 655000], Y[10000, 1185000]\n",
      "\n",
      "Step 2: Loading transmission lines\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\888\\anaconda3\\Lib\\site-packages\\pyogrio\\raw.py:198: RuntimeWarning: Several features with id = 3993385 have been found. Altering it to be unique. This warning will not be emitted anymore for this layer\n",
      "  return ogr_read(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 14654 transmission lines\n",
      "\n",
      "Step 3: Extracting line coordinates and building spatial index\n",
      "Extracted 226,154 coordinate points from lines\n",
      "Densifying line segments...\n",
      "Densified to 603,492 points (100m interval)\n",
      "Building KDTree spatial index...\n",
      "KDTree built successfully\n",
      "\n",
      "Step 4: Calculating precise Euclidean distance for each cell center\n",
      "This may take a few minutes...\n",
      "Distance calculation complete in 0 seconds\n",
      "Distance range: 3.6 - 285397.2 m\n",
      "\n",
      "Step 5: Calculating suitability scores\n",
      "Using EXPONENTIAL DECAY scoring:\n",
      "  Formula: Score = 10.0 × exp(-distance / λ)\n",
      "  λ (lambda) = 7.21 km\n",
      "  \n",
      "  Distance examples:\n",
      "    0 km   → Score = 10.00\n",
      "    7.21 km → Score = 3.68 (≈37% of max)\n",
      "    14.42 km → Score = 1.35 (≈14% of max)\n",
      "    21.63 km → Score = 0.50 (≈5% of max)\n",
      "\n",
      "Score distribution:\n",
      "  Score ≥  8.0:   2,709 cells (  8.8%) [d ≤   1.6 km]\n",
      "  Score ≥  6.0:   5,194 cells ( 16.9%) [d ≤   3.7 km]\n",
      "  Score ≥  4.0:   7,326 cells ( 23.8%) [d ≤   6.6 km]\n",
      "  Score ≥  2.0:   9,601 cells ( 31.2%) [d ≤  11.6 km]\n",
      "  Score ≥  1.0:  11,080 cells ( 36.0%) [d ≤  16.6 km]\n",
      "  Score ≥  0.5:  12,285 cells ( 39.9%) [d ≤  21.6 km]\n",
      "\n",
      "Mean score: 2.053\n",
      "Median score: 0.050\n",
      "\n",
      "Step 6: Applying UK land mask\n",
      "Creating land mask (this may take a moment)...\n",
      "Valid land cells: 9,758 (31.7%)\n",
      "\n",
      "Step 7: Statistics\n",
      "\n",
      "Distance statistics (km):\n",
      "  Min: 0.004\n",
      "  Max: 85.810\n",
      "  Mean: 6.047\n",
      "  Median: 3.521\n",
      "  Std: 7.487\n",
      "\n",
      "Score statistics:\n",
      "  Min: 0.000\n",
      "  Max: 9.995\n",
      "  Mean: 5.706\n",
      "  Median: 6.136\n",
      "  Std: 2.874\n",
      "\n",
      "Number of unique distance values: 9,757\n",
      "✓ Continuous distance values detected (good!)\n",
      "Sample values: [0.00358077 0.00723508 0.00739401 0.00808287 0.0087364  0.00947005\n",
      " 0.01030679 0.0109152  0.01101484 0.01542488]\n",
      "\n",
      "Score-Distance relationship (exponential decay with λ=7.21):\n",
      "  Distance  0.00 km → Score 10.00\n",
      "  Distance  1.00 km → Score  8.70\n",
      "  Distance  2.00 km → Score  7.58\n",
      "  Distance  5.00 km → Score  5.00\n",
      "  Distance  7.21 km → Score  3.68\n",
      "  Distance 10.00 km → Score  2.50\n",
      "  Distance 15.00 km → Score  1.25\n",
      "  Distance 20.00 km → Score  0.62\n",
      "  Distance 30.00 km → Score  0.16\n",
      "\n",
      "Step 8: Saving GeoTIFF files\n",
      "Saved: D:\\BENV0093\\outputs\\grid_distance.tif\n",
      "Saved: D:\\BENV0093\\outputs\\grid_suitability_score.tif\n",
      "\n",
      "================================================================================\n",
      "PROCESSING COMPLETE - EXPONENTIAL DECAY SCORING\n",
      "================================================================================\n",
      "\n",
      "Scoring method: Exponential decay\n",
      "  Formula: Score = 10.0 × exp(-d / 7.21)\n",
      "  λ parameter: 7.21 km\n",
      "  \n",
      "Advantages of exponential decay:\n",
      "  • Smooth continuous scoring (no discrete thresholds)\n",
      "  • Reflects real-world cost curves (exponential growth)\n",
      "  • At λ distance (7.21 km), score drops to 37% of maximum\n",
      "  • Natural decay - score asymptotically approaches zero\n",
      "  \n",
      "Distance statistics: 0.0 - 85.8 km (mean: 6.0 km)\n",
      "Score statistics: 0.00 - 10.00 (mean: 5.71)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.transform import Affine\n",
    "from scipy.spatial import cKDTree\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from shapely.geometry import Point\n",
    "import time\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"GRID DISTANCE PROCESSING (PRECISE VECTOR METHOD)\")\n",
    "print(\"With EXPONENTIAL DECAY SCORING (λ=7.21)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "BASE_DIR = Path('D:/BENV0093')\n",
    "DATASET_DIR = BASE_DIR / 'Dateset_T2'\n",
    "OUTPUT_DIR = BASE_DIR / 'outputs'\n",
    "\n",
    "TRANSMISSION_LINES = DATASET_DIR / 'TransmissionLines' / 'uk_transmission_lines.geojson'\n",
    "UK_BOUNDARY_SHP = BASE_DIR / 'UK_ITL1_Boundaries.shp'\n",
    "REFERENCE_GRID_PKL = OUTPUT_DIR / 'reference_grid.pkl'\n",
    "\n",
    "GRID_DISTANCE_TIF = OUTPUT_DIR / 'grid_distance.tif'\n",
    "GRID_SCORE_TIF = OUTPUT_DIR / 'grid_suitability_score.tif'\n",
    "\n",
    "# NEW: Exponential decay parameters\n",
    "LAMBDA_DECAY = 7.21  # Decay parameter in km\n",
    "MAX_SCORE = 10.0\n",
    "NODATA_VALUE = -9999\n",
    "CRS_EPSG = 27700\n",
    "\n",
    "if not TRANSMISSION_LINES.exists():\n",
    "    print(f\"ERROR: Transmission lines not found: {TRANSMISSION_LINES}\")\n",
    "    exit(1)\n",
    "\n",
    "# Step 1: Load reference grid\n",
    "print(\"\\nStep 1: Loading reference grid\")\n",
    "with open(REFERENCE_GRID_PKL, 'rb') as f:\n",
    "    ref = pickle.load(f)\n",
    "\n",
    "rows, cols = ref['shape']\n",
    "pixel_size = ref['pixel_size']\n",
    "x_spacing, y_spacing = pixel_size\n",
    "extent = ref['extent']\n",
    "\n",
    "x_min = extent[0]\n",
    "y_max = extent[3]\n",
    "\n",
    "transform = Affine(\n",
    "    pixel_size[0], 0, extent[0],\n",
    "    0, -abs(pixel_size[1]), extent[3]\n",
    ")\n",
    "\n",
    "print(f\"Shape: {rows} x {cols}\")\n",
    "print(f\"Pixel size: {x_spacing:.2f} x {y_spacing:.2f} m\")\n",
    "print(f\"Extent: X[{extent[0]:.0f}, {extent[1]:.0f}], Y[{extent[2]:.0f}, {extent[3]:.0f}]\")\n",
    "\n",
    "# Step 2: Load transmission lines\n",
    "print(\"\\nStep 2: Loading transmission lines\")\n",
    "transmission_lines = gpd.read_file(TRANSMISSION_LINES)\n",
    "if transmission_lines.crs.to_epsg() != CRS_EPSG:\n",
    "    transmission_lines = transmission_lines.to_crs(f'EPSG:{CRS_EPSG}')\n",
    "print(f\"Loaded {len(transmission_lines)} transmission lines\")\n",
    "\n",
    "# Step 3: Extract line coordinates and build KDTree\n",
    "print(\"\\nStep 3: Extracting line coordinates and building spatial index\")\n",
    "\n",
    "all_coords = []\n",
    "for idx, line in transmission_lines.iterrows():\n",
    "    geom = line.geometry\n",
    "    if geom.geom_type == 'LineString':\n",
    "        coords = np.array(geom.coords)\n",
    "        all_coords.append(coords)\n",
    "    elif geom.geom_type == 'MultiLineString':\n",
    "        for g in geom.geoms:\n",
    "            coords = np.array(g.coords)\n",
    "            all_coords.append(coords)\n",
    "\n",
    "line_points = np.vstack(all_coords)\n",
    "print(f\"Extracted {len(line_points):,} coordinate points from lines\")\n",
    "\n",
    "print(\"Densifying line segments...\")\n",
    "densified_points = []\n",
    "densify_interval = 100\n",
    "\n",
    "for coords_array in all_coords:\n",
    "    for i in range(len(coords_array) - 1):\n",
    "        p1 = coords_array[i]\n",
    "        p2 = coords_array[i + 1]\n",
    "        \n",
    "        segment_length = np.sqrt((p2[0] - p1[0])**2 + (p2[1] - p1[1])**2)\n",
    "        n_points = max(1, int(segment_length / densify_interval))\n",
    "        \n",
    "        for j in range(n_points + 1):\n",
    "            t = j / n_points\n",
    "            point = p1 + t * (p2 - p1)\n",
    "            densified_points.append(point)\n",
    "\n",
    "line_points_dense = np.array(densified_points)\n",
    "print(f\"Densified to {len(line_points_dense):,} points ({densify_interval}m interval)\")\n",
    "\n",
    "print(\"Building KDTree spatial index...\")\n",
    "tree = cKDTree(line_points_dense)\n",
    "print(\"KDTree built successfully\")\n",
    "\n",
    "# Step 4: Calculate precise distance for each grid cell center\n",
    "print(\"\\nStep 4: Calculating precise Euclidean distance for each cell center\")\n",
    "print(\"This may take a few minutes...\")\n",
    "\n",
    "distance_meters = np.full((rows, cols), np.nan, dtype=np.float32)\n",
    "\n",
    "start_time = time.time()\n",
    "processed = 0\n",
    "total_cells = rows * cols\n",
    "\n",
    "batch_size = 10000\n",
    "batch_coords = []\n",
    "batch_indices = []\n",
    "\n",
    "for r in range(rows):\n",
    "    for c in range(cols):\n",
    "        x_center = x_min + (c + 0.5) * x_spacing\n",
    "        y_center = y_max - (r + 0.5) * y_spacing\n",
    "        \n",
    "        batch_coords.append([x_center, y_center])\n",
    "        batch_indices.append((r, c))\n",
    "        \n",
    "        if len(batch_coords) >= batch_size:\n",
    "            distances, _ = tree.query(batch_coords)\n",
    "            \n",
    "            for (row_idx, col_idx), dist in zip(batch_indices, distances):\n",
    "                distance_meters[row_idx, col_idx] = dist\n",
    "            \n",
    "            batch_coords = []\n",
    "            batch_indices = []\n",
    "            \n",
    "            processed += batch_size\n",
    "            if processed % 100000 == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                progress = processed / total_cells * 100\n",
    "                print(f\"  Progress: {progress:.1f}% ({processed:,}/{total_cells:,}) - {elapsed:.0f}s elapsed\")\n",
    "\n",
    "if batch_coords:\n",
    "    distances, _ = tree.query(batch_coords)\n",
    "    for (row_idx, col_idx), dist in zip(batch_indices, distances):\n",
    "        distance_meters[row_idx, col_idx] = dist\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"Distance calculation complete in {elapsed:.0f} seconds\")\n",
    "print(f\"Distance range: {np.nanmin(distance_meters):.1f} - {np.nanmax(distance_meters):.1f} m\")\n",
    "\n",
    "# Step 5: Calculate suitability scores using EXPONENTIAL DECAY\n",
    "print(\"\\nStep 5: Calculating suitability scores\")\n",
    "print(f\"Using EXPONENTIAL DECAY scoring:\")\n",
    "print(f\"  Formula: Score = {MAX_SCORE} × exp(-distance / λ)\")\n",
    "print(f\"  λ (lambda) = {LAMBDA_DECAY} km\")\n",
    "print(f\"  \")\n",
    "print(f\"  Distance examples:\")\n",
    "print(f\"    0 km   → Score = {MAX_SCORE * np.exp(-0/LAMBDA_DECAY):.2f}\")\n",
    "print(f\"    {LAMBDA_DECAY:.2f} km → Score = {MAX_SCORE * np.exp(-1):.2f} (≈37% of max)\")\n",
    "print(f\"    {LAMBDA_DECAY*2:.2f} km → Score = {MAX_SCORE * np.exp(-2):.2f} (≈14% of max)\")\n",
    "print(f\"    {LAMBDA_DECAY*3:.2f} km → Score = {MAX_SCORE * np.exp(-3):.2f} (≈5% of max)\")\n",
    "\n",
    "suitability_score = np.zeros_like(distance_meters, dtype=np.float32)\n",
    "\n",
    "# Create valid mask (non-NaN values)\n",
    "valid_mask = ~np.isnan(distance_meters)\n",
    "\n",
    "# Convert distance to km\n",
    "distance_km = distance_meters / 1000.0\n",
    "\n",
    "# Apply exponential decay: Score = MAX_SCORE × exp(-distance_km / lambda)\n",
    "suitability_score[valid_mask] = MAX_SCORE * np.exp(-distance_km[valid_mask] / LAMBDA_DECAY)\n",
    "\n",
    "# Statistics on score distribution\n",
    "print(f\"\\nScore distribution:\")\n",
    "for score_threshold in [10, 8, 6, 4, 2, 1, 0.5]:\n",
    "    count = np.sum(suitability_score[valid_mask] >= score_threshold)\n",
    "    pct = count / valid_mask.sum() * 100\n",
    "    if count > 0:\n",
    "        # Find distance range for this score\n",
    "        cells_at_threshold = distance_km[valid_mask & (suitability_score >= score_threshold)]\n",
    "        max_dist = cells_at_threshold.max()\n",
    "        print(f\"  Score ≥ {score_threshold:4.1f}: {count:7,} cells ({pct:5.1f}%) [d ≤ {max_dist:5.1f} km]\")\n",
    "\n",
    "print(f\"\\nMean score: {suitability_score[valid_mask].mean():.3f}\")\n",
    "print(f\"Median score: {np.median(suitability_score[valid_mask]):.3f}\")\n",
    "\n",
    "# Step 6: Apply UK land mask\n",
    "print(\"\\nStep 6: Applying UK land mask\")\n",
    "uk_boundary = gpd.read_file(UK_BOUNDARY_SHP)\n",
    "if uk_boundary.crs.to_epsg() != CRS_EPSG:\n",
    "    uk_boundary = uk_boundary.to_crs(f'EPSG:{CRS_EPSG}')\n",
    "\n",
    "print(\"Creating land mask (this may take a moment)...\")\n",
    "land_mask = np.zeros((rows, cols), dtype=bool)\n",
    "\n",
    "uk_dissolved = uk_boundary.dissolve()\n",
    "uk_geom = uk_dissolved.geometry.iloc[0]\n",
    "\n",
    "batch_points = []\n",
    "batch_indices = []\n",
    "batch_size_mask = 50000\n",
    "\n",
    "for r in range(rows):\n",
    "    for c in range(cols):\n",
    "        y = y_max - r * y_spacing - y_spacing / 2\n",
    "        x = x_min + c * x_spacing + x_spacing / 2\n",
    "        \n",
    "        batch_points.append(Point(x, y))\n",
    "        batch_indices.append((r, c))\n",
    "        \n",
    "        if len(batch_points) >= batch_size_mask:\n",
    "            for point, (row_idx, col_idx) in zip(batch_points, batch_indices):\n",
    "                if uk_geom.contains(point):\n",
    "                    land_mask[row_idx, col_idx] = True\n",
    "            \n",
    "            batch_points = []\n",
    "            batch_indices = []\n",
    "\n",
    "if batch_points:\n",
    "    for point, (row_idx, col_idx) in zip(batch_points, batch_indices):\n",
    "        if uk_geom.contains(point):\n",
    "            land_mask[row_idx, col_idx] = True\n",
    "\n",
    "distance_meters[~land_mask] = np.nan\n",
    "suitability_score[~land_mask] = np.nan\n",
    "\n",
    "valid_cells = (~np.isnan(distance_meters)).sum()\n",
    "print(f\"Valid land cells: {valid_cells:,} ({valid_cells/(rows*cols)*100:.1f}%)\")\n",
    "\n",
    "# Step 7: Statistics\n",
    "print(\"\\nStep 7: Statistics\")\n",
    "valid_dist = distance_meters[~np.isnan(distance_meters)] / 1000\n",
    "valid_scores = suitability_score[~np.isnan(suitability_score)]\n",
    "\n",
    "print(f\"\\nDistance statistics (km):\")\n",
    "print(f\"  Min: {valid_dist.min():.3f}\")\n",
    "print(f\"  Max: {valid_dist.max():.3f}\")\n",
    "print(f\"  Mean: {valid_dist.mean():.3f}\")\n",
    "print(f\"  Median: {np.median(valid_dist):.3f}\")\n",
    "print(f\"  Std: {valid_dist.std():.3f}\")\n",
    "\n",
    "print(f\"\\nScore statistics:\")\n",
    "print(f\"  Min: {valid_scores.min():.3f}\")\n",
    "print(f\"  Max: {valid_scores.max():.3f}\")\n",
    "print(f\"  Mean: {valid_scores.mean():.3f}\")\n",
    "print(f\"  Median: {np.median(valid_scores):.3f}\")\n",
    "print(f\"  Std: {valid_scores.std():.3f}\")\n",
    "\n",
    "unique_distances = np.unique(valid_dist)\n",
    "print(f\"\\nNumber of unique distance values: {len(unique_distances):,}\")\n",
    "if len(unique_distances) < 100:\n",
    "    print(\"WARNING: Very few unique values detected\")\n",
    "    print(f\"Sample values: {unique_distances[:10]}\")\n",
    "else:\n",
    "    print(f\"✓ Continuous distance values detected (good!)\")\n",
    "    print(f\"Sample values: {np.sort(valid_dist)[:10]}\")\n",
    "\n",
    "# Show score-distance relationship examples\n",
    "print(f\"\\nScore-Distance relationship (exponential decay with λ={LAMBDA_DECAY}):\")\n",
    "example_distances = [0, 1, 2, 5, 7.21, 10, 15, 20, 30]\n",
    "for d in example_distances:\n",
    "    score = MAX_SCORE * np.exp(-d / LAMBDA_DECAY)\n",
    "    print(f\"  Distance {d:5.2f} km → Score {score:5.2f}\")\n",
    "\n",
    "# Step 8: Save GeoTIFF files\n",
    "print(\"\\nStep 8: Saving GeoTIFF files\")\n",
    "metadata = {\n",
    "    'driver': 'GTiff',\n",
    "    'dtype': 'float32',\n",
    "    'nodata': NODATA_VALUE,\n",
    "    'width': cols,\n",
    "    'height': rows,\n",
    "    'count': 1,\n",
    "    'crs': f'EPSG:{CRS_EPSG}',\n",
    "    'transform': transform,\n",
    "    'compress': 'lzw'\n",
    "}\n",
    "\n",
    "distance_save = np.where(np.isnan(distance_meters), NODATA_VALUE, distance_meters)\n",
    "with rasterio.open(GRID_DISTANCE_TIF, 'w', **metadata) as dst:\n",
    "    dst.write(distance_save.astype('float32'), 1)\n",
    "print(f\"Saved: {GRID_DISTANCE_TIF}\")\n",
    "\n",
    "score_save = np.where(np.isnan(suitability_score), NODATA_VALUE, suitability_score)\n",
    "with rasterio.open(GRID_SCORE_TIF, 'w', **metadata) as dst:\n",
    "    dst.write(score_save.astype('float32'), 1)\n",
    "print(f\"Saved: {GRID_SCORE_TIF}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PROCESSING COMPLETE - EXPONENTIAL DECAY SCORING\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nScoring method: Exponential decay\")\n",
    "print(f\"  Formula: Score = {MAX_SCORE} × exp(-d / {LAMBDA_DECAY})\")\n",
    "print(f\"  λ parameter: {LAMBDA_DECAY} km\")\n",
    "print(f\"  \")\n",
    "print(f\"Advantages of exponential decay:\")\n",
    "print(f\"  • Smooth continuous scoring (no discrete thresholds)\")\n",
    "print(f\"  • Reflects real-world cost curves (exponential growth)\")\n",
    "print(f\"  • At λ distance ({LAMBDA_DECAY} km), score drops to 37% of maximum\")\n",
    "print(f\"  • Natural decay - score asymptotically approaches zero\")\n",
    "print(f\"  \")\n",
    "print(f\"Distance statistics: {valid_dist.min():.1f} - {valid_dist.max():.1f} km (mean: {valid_dist.mean():.1f} km)\")\n",
    "print(f\"Score statistics: {valid_scores.min():.2f} - {valid_scores.max():.2f} (mean: {valid_scores.mean():.2f})\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33709b2b-a8d8-49f0-996a-d9fd29eea9ca",
   "metadata": {},
   "source": [
    "Grid Distance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df1fc9fe-1938-4e6d-ab3f-9aa572336086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "GRID DISTANCE VISUALIZATION\n",
      "Exponential Decay Scoring (λ=7.21 km)\n",
      "================================================================================\n",
      "\n",
      "Loading reference grid\n",
      "Shape: 235 x 131\n",
      "Extent: X[0, 655000], Y[10000, 1185000]\n",
      "\n",
      "Loading raster data\n",
      "Loading vector data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\888\\anaconda3\\Lib\\site-packages\\pyogrio\\raw.py:198: RuntimeWarning: Several features with id = 3993385 have been found. Altering it to be unique. This warning will not be emitted anymore for this layer\n",
      "  return ogr_read(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raster: 235 x 131\n",
      "HV Lines: 14654\n",
      "\n",
      "================================================================================\n",
      "MAP 1: Distance to Transmission Lines\n",
      "================================================================================\n",
      "Saved: D:\\BENV0093\\outputs\\map3_grid_distance.png\n",
      "\n",
      "================================================================================\n",
      "MAP 2: Grid Connection Suitability Score (Exponential Decay)\n",
      "================================================================================\n",
      "Saved: D:\\BENV0093\\outputs\\map4_grid_suitability_score.png\n",
      "\n",
      "================================================================================\n",
      "VISUALIZATION COMPLETE\n",
      "================================================================================\n",
      "\n",
      "Scoring Method: EXPONENTIAL DECAY\n",
      "  Formula: Score = 10 × exp(-distance / 7.21)\n",
      "  λ parameter: 7.21 km\n",
      "  WLC Weight: 34.75%\n",
      "  \n",
      "Output files:\n",
      "  D:\\BENV0093\\outputs\\map3_grid_distance.png\n",
      "  D:\\BENV0093\\outputs\\map4_grid_suitability_score.png\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.patches as mpatches\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"GRID DISTANCE VISUALIZATION\")\n",
    "print(\"Exponential Decay Scoring (λ=7.21 km)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "BASE_DIR = Path('D:/BENV0093')\n",
    "OUTPUT_DIR = BASE_DIR / 'outputs'\n",
    "\n",
    "GRID_DISTANCE_TIF = OUTPUT_DIR / 'grid_distance.tif'\n",
    "GRID_SCORE_TIF = OUTPUT_DIR / 'grid_suitability_score.tif'\n",
    "UK_BOUNDARY_SHP = BASE_DIR / 'UK_ITL1_Boundaries.shp'\n",
    "TRANSMISSION_LINES = BASE_DIR / 'Dateset_T2' / 'TransmissionLines' / 'uk_transmission_lines.geojson'\n",
    "REFERENCE_GRID_PKL = OUTPUT_DIR / 'reference_grid.pkl'\n",
    "\n",
    "MAP1_FILE = OUTPUT_DIR / 'map3_grid_distance.png'\n",
    "MAP2_FILE = OUTPUT_DIR / 'map4_grid_suitability_score.png'\n",
    "\n",
    "NODATA_VALUE = -9999\n",
    "CRS_EPSG = 27700\n",
    "LAMBDA_DECAY = 7.21  # Exponential decay parameter\n",
    "\n",
    "# Load reference grid\n",
    "print(\"\\nLoading reference grid\")\n",
    "with open(REFERENCE_GRID_PKL, 'rb') as f:\n",
    "    ref_grid = pickle.load(f)\n",
    "\n",
    "rows, cols = ref_grid['shape']\n",
    "pixel_size = ref_grid['pixel_size']\n",
    "extent = ref_grid['extent']\n",
    "\n",
    "print(f\"Shape: {rows} x {cols}\")\n",
    "print(f\"Extent: X[{extent[0]:.0f}, {extent[1]:.0f}], Y[{extent[2]:.0f}, {extent[3]:.0f}]\")\n",
    "\n",
    "# Load rasters\n",
    "print(\"\\nLoading raster data\")\n",
    "with rasterio.open(GRID_DISTANCE_TIF) as src:\n",
    "    distance_meters = src.read(1)\n",
    "    distance_meters[distance_meters == NODATA_VALUE] = np.nan\n",
    "\n",
    "with rasterio.open(GRID_SCORE_TIF) as src:\n",
    "    suitability_score = src.read(1)\n",
    "    suitability_score[suitability_score == NODATA_VALUE] = np.nan\n",
    "\n",
    "distance_km = distance_meters / 1000\n",
    "\n",
    "# Load vectors\n",
    "print(\"Loading vector data\")\n",
    "uk_boundary = gpd.read_file(UK_BOUNDARY_SHP)\n",
    "if uk_boundary.crs.to_epsg() != CRS_EPSG:\n",
    "    uk_boundary = uk_boundary.to_crs(f'EPSG:{CRS_EPSG}')\n",
    "\n",
    "transmission_lines = gpd.read_file(TRANSMISSION_LINES)\n",
    "if transmission_lines.crs.to_epsg() != CRS_EPSG:\n",
    "    transmission_lines = transmission_lines.to_crs(f'EPSG:{CRS_EPSG}')\n",
    "\n",
    "print(f\"Raster: {rows} x {cols}\")\n",
    "print(f\"HV Lines: {len(transmission_lines)}\")\n",
    "\n",
    "# Map 1: Distance to Transmission Lines\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MAP 1: Distance to Transmission Lines\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 18), dpi=300)\n",
    "ax.set_facecolor('#e6f2ff')\n",
    "ax.grid(True, alpha=0.3, linestyle='--', linewidth=0.5, color='gray', zorder=1)\n",
    "\n",
    "distance_colors = [\n",
    "    '#000080', '#0000CD', '#4169E1', '#1E90FF', '#87CEEB',\n",
    "    '#9370DB', '#BA55D3', '#FF69B4', '#FF6347', '#FF8C00', '#FFA500'\n",
    "]\n",
    "dist_cmap = LinearSegmentedColormap.from_list('distance_smooth', distance_colors, N=256)\n",
    "\n",
    "im = ax.imshow(distance_km, cmap=dist_cmap,\n",
    "               extent=extent, origin='upper',\n",
    "               vmin=0, vmax=60,\n",
    "               interpolation='bilinear', zorder=2)\n",
    "\n",
    "uk_boundary.boundary.plot(ax=ax, color='black', linewidth=1.5, zorder=10)\n",
    "transmission_lines.plot(ax=ax, color='darkred', linewidth=0.4, alpha=0.6, zorder=11)\n",
    "\n",
    "ax.set_xlabel('Easting (m)', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Northing (m)', fontsize=14, fontweight='bold')\n",
    "ax.set_title('Distance to Nearest High-Voltage Transmission Line\\n(Precise Vector-Based Calculation)',\n",
    "             fontsize=18, fontweight='bold', pad=20)\n",
    "ax.ticklabel_format(style='plain')\n",
    "ax.tick_params(labelsize=11)\n",
    "\n",
    "cbar = plt.colorbar(im, ax=ax, pad=0.02, fraction=0.046, shrink=0.8)\n",
    "cbar.set_label('Distance to Grid (km)', fontsize=13, fontweight='bold', labelpad=10)\n",
    "cbar.ax.tick_params(labelsize=10)\n",
    "\n",
    "# Add threshold lines at key distances\n",
    "cbar.ax.axhline(y=LAMBDA_DECAY, color='yellow', linestyle='--', linewidth=2, alpha=0.8)\n",
    "cbar.ax.text(1.35, LAMBDA_DECAY, f'λ={LAMBDA_DECAY}km', fontsize=8, va='center',\n",
    "             bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))\n",
    "\n",
    "valid_dist = distance_km[~np.isnan(distance_km)]\n",
    "legend_elements = [\n",
    "    mpatches.Patch(color='#0000CD', label=f'Very close (0-2 km): {((valid_dist <= 2).sum()/len(valid_dist)*100):.1f}%'),\n",
    "    mpatches.Patch(color='#1E90FF', label=f'Close (2-7 km): {(((valid_dist > 2) & (valid_dist <= 7)).sum()/len(valid_dist)*100):.1f}%'),\n",
    "    mpatches.Patch(color='#87CEEB', label=f'Moderate (7-15 km): {(((valid_dist > 7) & (valid_dist <= 15)).sum()/len(valid_dist)*100):.1f}%'),\n",
    "    mpatches.Patch(color='#BA55D3', label=f'Far (15-30 km): {(((valid_dist > 15) & (valid_dist <= 30)).sum()/len(valid_dist)*100):.1f}%'),\n",
    "    mpatches.Patch(color='#FF6347', label=f'Very far (30-50 km): {(((valid_dist > 30) & (valid_dist <= 50)).sum()/len(valid_dist)*100):.1f}%'),\n",
    "    mpatches.Patch(color='#FFA500', label=f'Extremely far (>50 km): {((valid_dist > 50).sum()/len(valid_dist)*100):.1f}%'),\n",
    "]\n",
    "\n",
    "legend = ax.legend(handles=legend_elements, loc='upper left',\n",
    "                   fontsize=9, framealpha=0.95, edgecolor='black',\n",
    "                   title='Distance Classification', title_fontsize=10,\n",
    "                   fancybox=True, shadow=True)\n",
    "\n",
    "stats_text = f\"\"\"Distance Statistics (km):\n",
    "Mean:   {valid_dist.mean():.1f}\n",
    "Median: {np.median(valid_dist):.1f}\n",
    "Std:    {valid_dist.std():.1f}\n",
    "Max:    {valid_dist.max():.1f}\n",
    "\n",
    "Method: Precise Vector\n",
    "KDTree + 100m densification\n",
    "Continuous meter-level accuracy\n",
    "\n",
    "Coverage (land only):\n",
    "<= 2 km:  {((valid_dist <= 2).sum()/len(valid_dist)*100):.1f}%\n",
    "<= 7 km:  {((valid_dist <= 7).sum()/len(valid_dist)*100):.1f}%\n",
    "<= 15 km: {((valid_dist <= 15).sum()/len(valid_dist)*100):.1f}%\n",
    "\n",
    "Grid: {rows}x{cols} cells\n",
    "HV Lines: {len(transmission_lines)}\n",
    "λ decay: {LAMBDA_DECAY} km\"\"\"\n",
    "\n",
    "props = dict(boxstyle='round', facecolor='white', alpha=0.95,\n",
    "             edgecolor='black', linewidth=1.5)\n",
    "ax.text(0.02, 0.15, stats_text, transform=ax.transAxes,\n",
    "        fontsize=9, verticalalignment='bottom', bbox=props,\n",
    "        fontfamily='monospace')\n",
    "\n",
    "scale_x = extent[0] + (extent[1] - extent[0]) * 0.05\n",
    "scale_y = extent[2] + (extent[3] - extent[2]) * 0.05\n",
    "scale_length = 100000\n",
    "\n",
    "ax.plot([scale_x, scale_x + scale_length], [scale_y, scale_y], 'k-', linewidth=3, zorder=15)\n",
    "ax.plot([scale_x, scale_x], [scale_y - 5000, scale_y + 5000], 'k-', linewidth=3, zorder=15)\n",
    "ax.plot([scale_x + scale_length, scale_x + scale_length],\n",
    "        [scale_y - 5000, scale_y + 5000], 'k-', linewidth=3, zorder=15)\n",
    "ax.text(scale_x + scale_length/2, scale_y + 12000, '100 km',\n",
    "        ha='center', fontsize=11, fontweight='bold',\n",
    "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.9), zorder=15)\n",
    "\n",
    "arrow_x = extent[1] - (extent[1] - extent[0]) * 0.05\n",
    "arrow_y = extent[3] - (extent[3] - extent[2]) * 0.08\n",
    "ax.annotate('N', xy=(arrow_x, arrow_y + 40000), xytext=(arrow_x, arrow_y),\n",
    "            arrowprops=dict(arrowstyle='->', lw=3, color='black'),\n",
    "            fontsize=16, fontweight='bold', ha='center', zorder=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(MAP1_FILE, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "print(f\"Saved: {MAP1_FILE}\")\n",
    "plt.close()\n",
    "\n",
    "# Map 2: Suitability Score\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MAP 2: Grid Connection Suitability Score (Exponential Decay)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 18), dpi=300)\n",
    "ax.set_facecolor('#e6f2ff')\n",
    "ax.grid(True, alpha=0.3, linestyle='--', linewidth=0.5, color='gray', zorder=1)\n",
    "\n",
    "suit_colors = [\n",
    "    '#a50026', '#d73027', '#f46d43', '#fdae61', '#fee08b',\n",
    "    '#ffffbf', '#d9ef8b', '#a6d96a', '#66bd63', '#1a9850', '#006837'\n",
    "]\n",
    "suit_cmap = LinearSegmentedColormap.from_list('suitability_smooth', suit_colors, N=256)\n",
    "\n",
    "im = ax.imshow(suitability_score, cmap=suit_cmap,\n",
    "               extent=extent, origin='upper',\n",
    "               vmin=0, vmax=10,\n",
    "               interpolation='bilinear', zorder=2)\n",
    "\n",
    "uk_boundary.boundary.plot(ax=ax, color='black', linewidth=1.5, zorder=10)\n",
    "transmission_lines.plot(ax=ax, color='darkred', linewidth=0.4, alpha=0.6, zorder=11)\n",
    "\n",
    "ax.set_xlabel('Easting (m)', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Northing (m)', fontsize=14, fontweight='bold')\n",
    "ax.set_title('Grid Connection Suitability Score (0-10)\\n(Exponential Decay Scoring: λ=7.21 km)',\n",
    "             fontsize=18, fontweight='bold', pad=20)\n",
    "ax.ticklabel_format(style='plain')\n",
    "ax.tick_params(labelsize=11)\n",
    "\n",
    "cbar = plt.colorbar(im, ax=ax, pad=0.02, fraction=0.046, shrink=0.8)\n",
    "cbar.set_label('Suitability Score', fontsize=13, fontweight='bold', labelpad=10)\n",
    "cbar.ax.tick_params(labelsize=10)\n",
    "\n",
    "# Add key score thresholds\n",
    "score_thresholds = [\n",
    "    (10 * np.exp(-1), 'yellow', f'37% (d=λ)'),\n",
    "    (10 * np.exp(-2), 'orange', f'14% (d=2λ)'),\n",
    "]\n",
    "for score, color, label in score_thresholds:\n",
    "    cbar.ax.axhline(y=score, color=color, linestyle=':', linewidth=1.5, alpha=0.7)\n",
    "\n",
    "valid_scores = suitability_score[~np.isnan(suitability_score)]\n",
    "\n",
    "# Calculate distance ranges for score categories\n",
    "def get_distance_for_score(score):\n",
    "    \"\"\"Calculate distance (km) that gives a specific score\"\"\"\n",
    "    if score >= 10:\n",
    "        return 0\n",
    "    return -LAMBDA_DECAY * np.log(score / 10)\n",
    "\n",
    "legend_elements = [\n",
    "    mpatches.Patch(color='#006837', \n",
    "                   label=f'Excellent (8-10): d ≤ {get_distance_for_score(8):.1f} km - {((valid_scores >= 8).sum()/len(valid_scores)*100):.1f}%'),\n",
    "    mpatches.Patch(color='#66bd63', \n",
    "                   label=f'Good (6-8): d = {get_distance_for_score(8):.1f}-{get_distance_for_score(6):.1f} km - {(((valid_scores >= 6) & (valid_scores < 8)).sum()/len(valid_scores)*100):.1f}%'),\n",
    "    mpatches.Patch(color='#d9ef8b', \n",
    "                   label=f'Fair (4-6): d = {get_distance_for_score(6):.1f}-{get_distance_for_score(4):.1f} km - {(((valid_scores >= 4) & (valid_scores < 6)).sum()/len(valid_scores)*100):.1f}%'),\n",
    "    mpatches.Patch(color='#fdae61', \n",
    "                   label=f'Marginal (2-4): d = {get_distance_for_score(4):.1f}-{get_distance_for_score(2):.1f} km - {(((valid_scores >= 2) & (valid_scores < 4)).sum()/len(valid_scores)*100):.1f}%'),\n",
    "    mpatches.Patch(color='#d73027', \n",
    "                   label=f'Poor (0-2): d > {get_distance_for_score(2):.1f} km - {(((valid_scores >= 0) & (valid_scores < 2)).sum()/len(valid_scores)*100):.1f}%'),\n",
    "]\n",
    "\n",
    "legend = ax.legend(handles=legend_elements, loc='upper left',\n",
    "                   fontsize=9, framealpha=0.95, edgecolor='black',\n",
    "                   title='Suitability Classes', title_fontsize=10,\n",
    "                   fancybox=True, shadow=True)\n",
    "\n",
    "stats_text = f\"\"\"Score Statistics:\n",
    "Mean:   {valid_scores.mean():.2f}\n",
    "Median: {np.median(valid_scores):.2f}\n",
    "Std:    {valid_scores.std():.2f}\n",
    "Min:    {valid_scores.min():.2f}\n",
    "Max:    {valid_scores.max():.2f}\n",
    "\n",
    "Scoring Formula:\n",
    "S = 10 × exp(-d / λ)\n",
    "\n",
    "where:\n",
    "  S = Suitability score (0-10)\n",
    "  d = Distance (km)\n",
    "  λ = {LAMBDA_DECAY} km (decay parameter)\n",
    "\n",
    "Key distances:\n",
    "  d = 0 km    → S = 10.00\n",
    "  d = {LAMBDA_DECAY:.2f} km → S = 3.68 (37%)\n",
    "  d = {LAMBDA_DECAY*2:.2f} km → S = 1.35 (14%)\n",
    "  d = {LAMBDA_DECAY*3:.2f} km → S = 0.50 (5%)\n",
    "\n",
    "Distribution:\n",
    "Excellent: {((valid_scores >= 8).sum()/len(valid_scores)*100):5.1f}%\n",
    "Good:      {(((valid_scores >= 6) & (valid_scores < 8)).sum()/len(valid_scores)*100):5.1f}%\n",
    "Fair:      {(((valid_scores >= 4) & (valid_scores < 6)).sum()/len(valid_scores)*100):5.1f}%\n",
    "Marginal:  {(((valid_scores >= 2) & (valid_scores < 4)).sum()/len(valid_scores)*100):5.1f}%\n",
    "Poor:      {((valid_scores < 2).sum()/len(valid_scores)*100):5.1f}%\n",
    "\n",
    "WLC Weight: 34.75%\n",
    "Grid: 275kV+400kV\n",
    "Method: Vector KDTree\"\"\"\n",
    "\n",
    "props = dict(boxstyle='round', facecolor='white', alpha=0.95,\n",
    "             edgecolor='black', linewidth=1.5)\n",
    "ax.text(0.02, 0.15, stats_text, transform=ax.transAxes,\n",
    "        fontsize=8.5, verticalalignment='bottom', bbox=props,\n",
    "        fontfamily='monospace')\n",
    "\n",
    "ax.plot([scale_x, scale_x + scale_length], [scale_y, scale_y], 'k-', linewidth=3, zorder=15)\n",
    "ax.plot([scale_x, scale_x], [scale_y - 5000, scale_y + 5000], 'k-', linewidth=3, zorder=15)\n",
    "ax.plot([scale_x + scale_length, scale_x + scale_length],\n",
    "        [scale_y - 5000, scale_y + 5000], 'k-', linewidth=3, zorder=15)\n",
    "ax.text(scale_x + scale_length/2, scale_y + 12000, '100 km',\n",
    "        ha='center', fontsize=11, fontweight='bold',\n",
    "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.9), zorder=15)\n",
    "\n",
    "ax.annotate('N', xy=(arrow_x, arrow_y + 40000), xytext=(arrow_x, arrow_y),\n",
    "            arrowprops=dict(arrowstyle='->', lw=3, color='black'),\n",
    "            fontsize=16, fontweight='bold', ha='center', zorder=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(MAP2_FILE, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "print(f\"Saved: {MAP2_FILE}\")\n",
    "plt.close()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VISUALIZATION COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nScoring Method: EXPONENTIAL DECAY\")\n",
    "print(f\"  Formula: Score = 10 × exp(-distance / {LAMBDA_DECAY})\")\n",
    "print(f\"  λ parameter: {LAMBDA_DECAY} km\")\n",
    "print(f\"  WLC Weight: 34.75%\")\n",
    "print(f\"  \")\n",
    "print(f\"Output files:\")\n",
    "print(f\"  {MAP1_FILE}\")\n",
    "print(f\"  {MAP2_FILE}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debe4d23-991f-4675-8034-0f1081462802",
   "metadata": {},
   "source": [
    "Roads Distance Processing\n",
    "Calculates distance to major roads and suitability scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab7ab085-9e9e-426f-b43e-2a206cd6afc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ROADS DISTANCE PROCESSING (PRECISE VECTOR METHOD)\n",
      "================================================================================\n",
      "\n",
      "Step 1: Loading reference grid\n",
      "Shape: 235 x 131\n",
      "Pixel size: 5000.00 x 5000.00 m\n",
      "Extent: X[0, 655000], Y[10000, 1185000]\n",
      "\n",
      "Step 2: Loading and filtering major roads\n",
      "Total roads loaded: 120146\n",
      "Major roads (motorway, trunk, primary): 120146\n",
      "Roads within study area: 120120\n",
      "Total road length: 28636 km\n",
      "\n",
      "Step 3: Extracting road coordinates for precise distance calculation\n",
      "Extracted 736,721 coordinate points from roads\n",
      "Densifying road segments...\n",
      "Densified to 1,268,659 points (100m interval)\n",
      "Building KDTree spatial index...\n",
      "KDTree built successfully\n",
      "\n",
      "Step 4: Calculating precise Euclidean distance for each cell center\n",
      "This may take a few minutes...\n",
      "Distance calculation complete in 0 seconds\n",
      "Distance range: 4.0 - 392162.9 m\n",
      "\n",
      "Step 5: Calculating suitability scores\n",
      "Using refined thresholds:\n",
      "  Excellent (score=10): d ≤ 1.0 km\n",
      "  Linear decay: 1.0 km < d ≤ 10.0 km\n",
      "  Unsuitable (score=0): d > 10.0 km\n",
      "Score distribution:\n",
      "  d ≤ 1.0km (score=10): 1,836 cells\n",
      "  1.0km < d ≤ 10.0km (linear decay): 7,030 cells\n",
      "  d > 10.0km (score=0): 21,919 cells\n",
      "\n",
      "Step 6: Applying UK land mask\n",
      "Valid land cells: 9,758 (31.7%)\n",
      "\n",
      "Step 7: Statistics\n",
      "\n",
      "Distance statistics (km):\n",
      "  Min: 0.004\n",
      "  Max: 255.391\n",
      "  Mean: 8.104\n",
      "  Median: 3.644\n",
      "  Std: 17.363\n",
      "\n",
      "Score statistics:\n",
      "  Min: 0.000\n",
      "  Max: 10.000\n",
      "  Mean: 5.864\n",
      "  Median: 7.062\n",
      "  Std: 3.822\n",
      "\n",
      "Distance distribution:\n",
      "    0-  1 km:   1,790 ( 18.3%)\n",
      "    1-  2 km:   1,382 ( 14.2%)\n",
      "    2-  5 km:   2,697 ( 27.6%)\n",
      "    5- 10 km:   1,935 ( 19.8%)\n",
      "   10- 15 km:     781 (  8.0%)\n",
      "   15- 20 km:     379 (  3.9%)\n",
      "  ≥ 20 km:     794 (  8.1%)\n",
      "\n",
      "Number of unique distance values: 9,757\n",
      "✓ Continuous distance values detected (good!)\n",
      "Sample values (first 10): [0.00402037 0.0072111  0.0077226  0.009      0.00911777 0.00970895\n",
      " 0.00995002 0.01022538 0.01028969 0.01030575]\n",
      "\n",
      "Step 8: Saving GeoTIFF files\n",
      "Saved: D:\\BENV0093\\outputs\\roads_distance.tif\n",
      "Saved: D:\\BENV0093\\outputs\\roads_suitability_score.tif\n",
      "\n",
      "================================================================================\n",
      "ROADS PROCESSING COMPLETE - PRECISE VECTOR METHOD\n",
      "================================================================================\n",
      "Distance: 0.0 - 255.4 km (mean: 8.1 km)\n",
      "Score: 0.00 - 10.00 (mean: 5.86)\n",
      "\n",
      "================================================================================\n",
      "KEY IMPROVEMENTS\n",
      "================================================================================\n",
      "1. Vector-based distance calculation (KDTree)\n",
      "   → Precise distances instead of raster quantization\n",
      "   → 9,757 unique values vs ~10 in old method\n",
      "\n",
      "2. Refined scoring thresholds\n",
      "   → Optimal: ≤1.0km (was 2-5km)\n",
      "   → Acceptable: 1.0-10.0km (was up to 15km)\n",
      "   → Better discrimination for site selection\n",
      "\n",
      "3. Maintained grid alignment\n",
      "   → Same 235×131 grid at 5000m resolution\n",
      "   → Compatible with all other criteria layers\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.transform import Affine\n",
    "from scipy.spatial import cKDTree  # NEW: Replace EDT with KDTree\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from shapely.geometry import Point\n",
    "import time  # NEW: For progress tracking\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ROADS DISTANCE PROCESSING (PRECISE VECTOR METHOD)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "BASE_DIR = Path('D:/BENV0093')\n",
    "DATASET_DIR = BASE_DIR / 'Dateset_T2'\n",
    "OUTPUT_DIR = BASE_DIR / 'outputs'\n",
    "\n",
    "ROADS_GEOJSON = DATASET_DIR / 'RoadNetwork' / 'uk_major_roads_complete.geojson'\n",
    "UK_BOUNDARY_SHP = BASE_DIR / 'UK_ITL1_Boundaries.shp'\n",
    "REFERENCE_GRID_PKL = OUTPUT_DIR / 'reference_grid.pkl'\n",
    "\n",
    "# NEW: Output to different files to avoid overwriting\n",
    "ROADS_DISTANCE_TIF = OUTPUT_DIR / 'roads_distance.tif'\n",
    "ROADS_SCORE_TIF = OUTPUT_DIR / 'roads_suitability_score.tif'\n",
    "\n",
    "# NEW: Refined thresholds for better discrimination\n",
    "THRESHOLD_NEAR = 1000      # 1 km (was 2-5 km range)\n",
    "THRESHOLD_FAR = 10000      # 10 km (was 15 km)\n",
    "MAX_SCORE = 10.0\n",
    "\n",
    "MAJOR_ROAD_CLASSES = ['motorway', 'motorway_link', 'trunk', 'trunk_link',\n",
    "                      'primary', 'primary_link', 'Major Road']\n",
    "\n",
    "NODATA_VALUE = -9999\n",
    "CRS_EPSG = 27700\n",
    "\n",
    "if not ROADS_GEOJSON.exists():\n",
    "    print(f\"ERROR: Roads file not found: {ROADS_GEOJSON}\")\n",
    "    exit(1)\n",
    "\n",
    "# Step 1: Load reference grid\n",
    "print(\"\\nStep 1: Loading reference grid\")\n",
    "with open(REFERENCE_GRID_PKL, 'rb') as f:\n",
    "    ref = pickle.load(f)\n",
    "\n",
    "rows, cols = ref['shape']\n",
    "pixel_size = ref['pixel_size']\n",
    "x_spacing, y_spacing = pixel_size\n",
    "extent = ref['extent']\n",
    "\n",
    "x_min = extent[0]\n",
    "y_max = extent[3]\n",
    "\n",
    "transform = Affine(\n",
    "    pixel_size[0], 0, extent[0],\n",
    "    0, -abs(pixel_size[1]), extent[3]\n",
    ")\n",
    "\n",
    "print(f\"Shape: {rows} x {cols}\")\n",
    "print(f\"Pixel size: {x_spacing:.2f} x {y_spacing:.2f} m\")\n",
    "print(f\"Extent: X[{extent[0]:.0f}, {extent[1]:.0f}], Y[{extent[2]:.0f}, {extent[3]:.0f}]\")\n",
    "\n",
    "# Step 2: Load and filter major roads\n",
    "print(\"\\nStep 2: Loading and filtering major roads\")\n",
    "roads = gpd.read_file(ROADS_GEOJSON)\n",
    "if roads.crs.to_epsg() != CRS_EPSG:\n",
    "    roads = roads.to_crs(f'EPSG:{CRS_EPSG}')\n",
    "\n",
    "print(f\"Total roads loaded: {len(roads)}\")\n",
    "\n",
    "roads_filtered = roads[roads['road_class'].isin(MAJOR_ROAD_CLASSES)]\n",
    "print(f\"Major roads (motorway, trunk, primary): {len(roads_filtered)}\")\n",
    "\n",
    "roads_clipped = roads_filtered.cx[extent[0]:extent[1], extent[2]:extent[3]]\n",
    "print(f\"Roads within study area: {len(roads_clipped)}\")\n",
    "\n",
    "total_length_km = roads_clipped.geometry.length.sum() / 1000\n",
    "print(f\"Total road length: {total_length_km:.0f} km\")\n",
    "\n",
    "# Step 3: Extract and densify road coordinates (NEW: KDTree method)\n",
    "print(\"\\nStep 3: Extracting road coordinates for precise distance calculation\")\n",
    "\n",
    "all_coords = []\n",
    "for idx, road in roads_clipped.iterrows():\n",
    "    geom = road.geometry\n",
    "    if geom.geom_type == 'LineString':\n",
    "        coords = np.array(geom.coords)\n",
    "        all_coords.append(coords)\n",
    "    elif geom.geom_type == 'MultiLineString':\n",
    "        for g in geom.geoms:\n",
    "            coords = np.array(g.coords)\n",
    "            all_coords.append(coords)\n",
    "\n",
    "# Concatenate all coordinates\n",
    "road_points = np.vstack(all_coords)\n",
    "print(f\"Extracted {len(road_points):,} coordinate points from roads\")\n",
    "\n",
    "# Densify road segments for better accuracy\n",
    "print(\"Densifying road segments...\")\n",
    "densified_points = []\n",
    "densify_interval = 100  # Add point every 100 meters\n",
    "\n",
    "for coords_array in all_coords:\n",
    "    for i in range(len(coords_array) - 1):\n",
    "        p1 = coords_array[i]\n",
    "        p2 = coords_array[i + 1]\n",
    "        \n",
    "        # Calculate segment length\n",
    "        segment_length = np.sqrt((p2[0] - p1[0])**2 + (p2[1] - p1[1])**2)\n",
    "        \n",
    "        # Number of intermediate points\n",
    "        n_points = max(1, int(segment_length / densify_interval))\n",
    "        \n",
    "        # Generate intermediate points\n",
    "        for j in range(n_points + 1):\n",
    "            t = j / n_points\n",
    "            point = p1 + t * (p2 - p1)\n",
    "            densified_points.append(point)\n",
    "\n",
    "road_points_dense = np.array(densified_points)\n",
    "print(f\"Densified to {len(road_points_dense):,} points ({densify_interval}m interval)\")\n",
    "\n",
    "# Build KDTree for fast nearest neighbor search\n",
    "print(\"Building KDTree spatial index...\")\n",
    "tree = cKDTree(road_points_dense)\n",
    "print(\"KDTree built successfully\")\n",
    "\n",
    "# Step 4: Calculate precise Euclidean distance for each grid cell center (NEW)\n",
    "print(\"\\nStep 4: Calculating precise Euclidean distance for each cell center\")\n",
    "print(\"This may take a few minutes...\")\n",
    "\n",
    "distance_meters = np.full((rows, cols), np.nan, dtype=np.float32)\n",
    "\n",
    "start_time = time.time()\n",
    "processed = 0\n",
    "total_cells = rows * cols\n",
    "\n",
    "# Process in batches for efficiency\n",
    "batch_size = 10000\n",
    "batch_coords = []\n",
    "batch_indices = []\n",
    "\n",
    "for r in range(rows):\n",
    "    for c in range(cols):\n",
    "        # Calculate cell center coordinates\n",
    "        x_center = x_min + (c + 0.5) * x_spacing\n",
    "        y_center = y_max - (r + 0.5) * y_spacing\n",
    "        \n",
    "        batch_coords.append([x_center, y_center])\n",
    "        batch_indices.append((r, c))\n",
    "        \n",
    "        if len(batch_coords) >= batch_size:\n",
    "            # Query KDTree for batch\n",
    "            distances, _ = tree.query(batch_coords)\n",
    "            \n",
    "            # Store results\n",
    "            for (row_idx, col_idx), dist in zip(batch_indices, distances):\n",
    "                distance_meters[row_idx, col_idx] = dist\n",
    "            \n",
    "            batch_coords = []\n",
    "            batch_indices = []\n",
    "            \n",
    "            processed += batch_size\n",
    "            if processed % 100000 == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                progress = processed / total_cells * 100\n",
    "                print(f\"  Progress: {progress:.1f}% ({processed:,}/{total_cells:,}) - {elapsed:.0f}s elapsed\")\n",
    "\n",
    "# Process remaining cells\n",
    "if batch_coords:\n",
    "    distances, _ = tree.query(batch_coords)\n",
    "    for (row_idx, col_idx), dist in zip(batch_indices, distances):\n",
    "        distance_meters[row_idx, col_idx] = dist\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"Distance calculation complete in {elapsed:.0f} seconds\")\n",
    "print(f\"Distance range: {np.nanmin(distance_meters):.1f} - {np.nanmax(distance_meters):.1f} m\")\n",
    "\n",
    "# Step 5: Calculate suitability scores with REFINED thresholds\n",
    "print(\"\\nStep 5: Calculating suitability scores\")\n",
    "print(f\"Using refined thresholds:\")\n",
    "print(f\"  Excellent (score=10): d ≤ {THRESHOLD_NEAR/1000} km\")\n",
    "print(f\"  Linear decay: {THRESHOLD_NEAR/1000} km < d ≤ {THRESHOLD_FAR/1000} km\")\n",
    "print(f\"  Unsuitable (score=0): d > {THRESHOLD_FAR/1000} km\")\n",
    "\n",
    "suitability_score = np.zeros_like(distance_meters, dtype=np.float32)\n",
    "\n",
    "# Create valid mask (non-NaN values)\n",
    "valid_mask = ~np.isnan(distance_meters)\n",
    "\n",
    "# Near zone: d <= 1 km → score = 10\n",
    "mask_near = valid_mask & (distance_meters <= THRESHOLD_NEAR)\n",
    "suitability_score[mask_near] = MAX_SCORE\n",
    "\n",
    "# Medium zone: 1 km < d <= 10 km → linear decay\n",
    "mask_medium = valid_mask & (distance_meters > THRESHOLD_NEAR) & (distance_meters <= THRESHOLD_FAR)\n",
    "suitability_score[mask_medium] = MAX_SCORE * (THRESHOLD_FAR - distance_meters[mask_medium]) / (THRESHOLD_FAR - THRESHOLD_NEAR)\n",
    "\n",
    "# Far zone: d > 10 km → score = 0\n",
    "mask_far = valid_mask & (distance_meters > THRESHOLD_FAR)\n",
    "suitability_score[mask_far] = 0.0\n",
    "\n",
    "print(f\"Score distribution:\")\n",
    "print(f\"  d ≤ {THRESHOLD_NEAR/1000}km (score=10): {mask_near.sum():,} cells\")\n",
    "print(f\"  {THRESHOLD_NEAR/1000}km < d ≤ {THRESHOLD_FAR/1000}km (linear decay): {mask_medium.sum():,} cells\")\n",
    "print(f\"  d > {THRESHOLD_FAR/1000}km (score=0): {mask_far.sum():,} cells\")\n",
    "\n",
    "# Step 6: Apply UK land mask (keep original logic)\n",
    "print(\"\\nStep 6: Applying UK land mask\")\n",
    "uk_boundary = gpd.read_file(UK_BOUNDARY_SHP)\n",
    "if uk_boundary.crs.to_epsg() != CRS_EPSG:\n",
    "    uk_boundary = uk_boundary.to_crs(f'EPSG:{CRS_EPSG}')\n",
    "\n",
    "land_mask = np.zeros((rows, cols), dtype=bool)\n",
    "for idx, region in uk_boundary.iterrows():\n",
    "    geom = region.geometry\n",
    "    bounds = geom.bounds\n",
    "    \n",
    "    col_start = max(0, int((bounds[0] - x_min) / x_spacing))\n",
    "    col_end = min(cols, int((bounds[2] - x_min) / x_spacing) + 1)\n",
    "    row_start = max(0, int((y_max - bounds[3]) / y_spacing))\n",
    "    row_end = min(rows, int((y_max - bounds[1]) / y_spacing) + 1)\n",
    "    \n",
    "    for r in range(row_start, row_end):\n",
    "        for c in range(col_start, col_end):\n",
    "            y = y_max - r * y_spacing - y_spacing / 2\n",
    "            x = x_min + c * x_spacing + x_spacing / 2\n",
    "            if geom.contains(Point(x, y)):\n",
    "                land_mask[r, c] = True\n",
    "\n",
    "distance_meters[~land_mask] = np.nan\n",
    "suitability_score[~land_mask] = np.nan\n",
    "\n",
    "valid_cells = (~np.isnan(distance_meters)).sum()\n",
    "print(f\"Valid land cells: {valid_cells:,} ({valid_cells/(rows*cols)*100:.1f}%)\")\n",
    "\n",
    "# Step 7: Statistics (NEW)\n",
    "print(\"\\nStep 7: Statistics\")\n",
    "valid_dist = distance_meters[~np.isnan(distance_meters)] / 1000\n",
    "valid_scores = suitability_score[~np.isnan(suitability_score)]\n",
    "\n",
    "print(f\"\\nDistance statistics (km):\")\n",
    "print(f\"  Min: {valid_dist.min():.3f}\")\n",
    "print(f\"  Max: {valid_dist.max():.3f}\")\n",
    "print(f\"  Mean: {valid_dist.mean():.3f}\")\n",
    "print(f\"  Median: {np.median(valid_dist):.3f}\")\n",
    "print(f\"  Std: {valid_dist.std():.3f}\")\n",
    "\n",
    "print(f\"\\nScore statistics:\")\n",
    "print(f\"  Min: {valid_scores.min():.3f}\")\n",
    "print(f\"  Max: {valid_scores.max():.3f}\")\n",
    "print(f\"  Mean: {valid_scores.mean():.3f}\")\n",
    "print(f\"  Median: {np.median(valid_scores):.3f}\")\n",
    "print(f\"  Std: {valid_scores.std():.3f}\")\n",
    "\n",
    "# Distribution by distance bins\n",
    "print(f\"\\nDistance distribution:\")\n",
    "bins = [0, 1, 2, 5, 10, 15, 20]\n",
    "for i in range(len(bins)-1):\n",
    "    count = np.sum((valid_dist >= bins[i]) & (valid_dist < bins[i+1]))\n",
    "    pct = count / len(valid_dist) * 100\n",
    "    print(f\"  {bins[i]:3.0f}-{bins[i+1]:3.0f} km: {count:7,} ({pct:5.1f}%)\")\n",
    "count_over = np.sum(valid_dist >= bins[-1])\n",
    "pct_over = count_over / len(valid_dist) * 100\n",
    "print(f\"  ≥{bins[-1]:3.0f} km: {count_over:7,} ({pct_over:5.1f}%)\")\n",
    "\n",
    "# Check for continuous values\n",
    "unique_distances = np.unique(valid_dist)\n",
    "print(f\"\\nNumber of unique distance values: {len(unique_distances):,}\")\n",
    "if len(unique_distances) < 100:\n",
    "    print(\"WARNING: Very few unique values detected\")\n",
    "    print(f\"Sample values: {unique_distances[:20]}\")\n",
    "else:\n",
    "    print(f\"✓ Continuous distance values detected (good!)\")\n",
    "    print(f\"Sample values (first 10): {np.sort(valid_dist)[:10]}\")\n",
    "\n",
    "# Step 8: Save GeoTIFF files\n",
    "print(\"\\nStep 8: Saving GeoTIFF files\")\n",
    "metadata = {\n",
    "    'driver': 'GTiff',\n",
    "    'dtype': 'float32',\n",
    "    'nodata': NODATA_VALUE,\n",
    "    'width': cols,\n",
    "    'height': rows,\n",
    "    'count': 1,\n",
    "    'crs': f'EPSG:{CRS_EPSG}',\n",
    "    'transform': transform,\n",
    "    'compress': 'lzw'\n",
    "}\n",
    "\n",
    "distance_save = np.where(np.isnan(distance_meters), NODATA_VALUE, distance_meters)\n",
    "with rasterio.open(ROADS_DISTANCE_TIF, 'w', **metadata) as dst:\n",
    "    dst.write(distance_save.astype('float32'), 1)\n",
    "print(f\"Saved: {ROADS_DISTANCE_TIF}\")\n",
    "\n",
    "score_save = np.where(np.isnan(suitability_score), NODATA_VALUE, suitability_score)\n",
    "with rasterio.open(ROADS_SCORE_TIF, 'w', **metadata) as dst:\n",
    "    dst.write(score_save.astype('float32'), 1)\n",
    "print(f\"Saved: {ROADS_SCORE_TIF}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ROADS PROCESSING COMPLETE - PRECISE VECTOR METHOD\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Distance: {valid_dist.min():.1f} - {valid_dist.max():.1f} km (mean: {valid_dist.mean():.1f} km)\")\n",
    "print(f\"Score: {valid_scores.min():.2f} - {valid_scores.max():.2f} (mean: {valid_scores.mean():.2f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY IMPROVEMENTS\")\n",
    "print(\"=\"*80)\n",
    "print(\"1. Vector-based distance calculation (KDTree)\")\n",
    "print(\"   → Precise distances instead of raster quantization\")\n",
    "print(f\"   → {len(unique_distances):,} unique values vs ~10 in old method\")\n",
    "print(\"\")\n",
    "print(\"2. Refined scoring thresholds\")\n",
    "print(f\"   → Optimal: ≤{THRESHOLD_NEAR/1000}km (was 2-5km)\")\n",
    "print(f\"   → Acceptable: {THRESHOLD_NEAR/1000}-{THRESHOLD_FAR/1000}km (was up to 15km)\")\n",
    "print(\"   → Better discrimination for site selection\")\n",
    "print(\"\")\n",
    "print(\"3. Maintained grid alignment\")\n",
    "print(f\"   → Same {rows}×{cols} grid at {x_spacing}m resolution\")\n",
    "print(\"   → Compatible with all other criteria layers\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6677e987-b602-44fd-8647-e89515928d0b",
   "metadata": {},
   "source": [
    "Roads Distance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adc9428a-36f9-4f69-b0e6-ff57d99d1e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ROADS DISTANCE VISUALIZATION\n",
      "================================================================================\n",
      "\n",
      "Loading reference grid\n",
      "Shape: 235 x 131\n",
      "Extent: X[0, 655000], Y[10000, 1185000]\n",
      "\n",
      "Loading raster data\n",
      "Loading vector data\n",
      "Raster: 235 x 131\n",
      "Roads: 120,120 segments\n",
      "\n",
      "================================================================================\n",
      "MAP 1: Distance to Major Roads\n",
      "================================================================================\n",
      "Saved: D:\\BENV0093\\outputs\\map5_roads_distance.png\n",
      "\n",
      "================================================================================\n",
      "MAP 2: Road Proximity Suitability Score\n",
      "================================================================================\n",
      "Saved: D:\\BENV0093\\outputs\\map6_roads_suitability_score.png\n",
      "\n",
      "================================================================================\n",
      "VISUALIZATION COMPLETE\n",
      "================================================================================\n",
      "Output files:\n",
      "  D:\\BENV0093\\outputs\\map5_roads_distance.png\n",
      "  D:\\BENV0093\\outputs\\map6_roads_suitability_score.png\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap, BoundaryNorm\n",
    "import matplotlib.patches as mpatches\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ROADS DISTANCE VISUALIZATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "BASE_DIR = Path('D:/BENV0093')\n",
    "OUTPUT_DIR = BASE_DIR / 'outputs'\n",
    "\n",
    "ROADS_DISTANCE_TIF = OUTPUT_DIR / 'roads_distance.tif'\n",
    "ROADS_SCORE_TIF = OUTPUT_DIR / 'roads_suitability_score.tif'\n",
    "UK_BOUNDARY_SHP = BASE_DIR / 'UK_ITL1_Boundaries.shp'\n",
    "ROADS_GEOJSON = BASE_DIR / 'Dateset_T2' / 'RoadNetwork' / 'uk_major_roads_complete.geojson'\n",
    "REFERENCE_GRID_PKL = OUTPUT_DIR / 'reference_grid.pkl'\n",
    "\n",
    "MAP1_FILE = OUTPUT_DIR / 'map5_roads_distance.png'\n",
    "MAP2_FILE = OUTPUT_DIR / 'map6_roads_suitability_score.png'\n",
    "\n",
    "MAJOR_ROAD_CLASSES = ['motorway', 'motorway_link', 'trunk', 'trunk_link',\n",
    "                      'primary', 'primary_link', 'Major Road']\n",
    "\n",
    "NODATA_VALUE = -9999\n",
    "CRS_EPSG = 27700\n",
    "\n",
    "# Load reference grid\n",
    "print(\"\\nLoading reference grid\")\n",
    "with open(REFERENCE_GRID_PKL, 'rb') as f:\n",
    "    ref_grid = pickle.load(f)\n",
    "\n",
    "rows, cols = ref_grid['shape']\n",
    "pixel_size = ref_grid['pixel_size']\n",
    "extent = ref_grid['extent']\n",
    "\n",
    "print(f\"Shape: {rows} x {cols}\")\n",
    "print(f\"Extent: X[{extent[0]:.0f}, {extent[1]:.0f}], Y[{extent[2]:.0f}, {extent[3]:.0f}]\")\n",
    "\n",
    "# Load rasters\n",
    "print(\"\\nLoading raster data\")\n",
    "with rasterio.open(ROADS_DISTANCE_TIF) as src:\n",
    "    distance_meters = src.read(1)\n",
    "    distance_meters[distance_meters == NODATA_VALUE] = np.nan\n",
    "\n",
    "with rasterio.open(ROADS_SCORE_TIF) as src:\n",
    "    score_data = src.read(1)\n",
    "    score_data[score_data == NODATA_VALUE] = np.nan\n",
    "\n",
    "distance_km = distance_meters / 1000\n",
    "\n",
    "# Load vectors\n",
    "print(\"Loading vector data\")\n",
    "uk_boundary = gpd.read_file(UK_BOUNDARY_SHP)\n",
    "if uk_boundary.crs.to_epsg() != CRS_EPSG:\n",
    "    uk_boundary = uk_boundary.to_crs(f'EPSG:{CRS_EPSG}')\n",
    "\n",
    "roads = gpd.read_file(ROADS_GEOJSON)\n",
    "if roads.crs.to_epsg() != CRS_EPSG:\n",
    "    roads = roads.to_crs(f'EPSG:{CRS_EPSG}')\n",
    "\n",
    "roads_filtered = roads[roads['road_class'].isin(MAJOR_ROAD_CLASSES)]\n",
    "roads_clipped = roads_filtered.cx[extent[0]:extent[1], extent[2]:extent[3]]\n",
    "roads_sample = roads_clipped.sample(min(3000, len(roads_clipped))) if len(roads_clipped) > 0 else roads_clipped\n",
    "\n",
    "print(f\"Raster: {rows} x {cols}\")\n",
    "print(f\"Roads: {len(roads_clipped):,} segments\")\n",
    "\n",
    "# Map 1: Distance to Major Roads\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MAP 1: Distance to Major Roads\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 18), dpi=300)\n",
    "ax.set_facecolor('#e6f2ff')\n",
    "ax.grid(True, alpha=0.3, linestyle='--', linewidth=0.5, color='gray', zorder=1)\n",
    "\n",
    "dist_colors = [\n",
    "    '#313695', '#4575b4', '#74add1', '#abd9e9', '#e0f3f8',\n",
    "    '#ffffbf', '#fee090', '#fdae61', '#f46d43', '#d73027', '#a50026'\n",
    "]\n",
    "dist_cmap = LinearSegmentedColormap.from_list('distance', dist_colors, N=256)\n",
    "dist_levels = np.arange(0, 30.5, 0.5)\n",
    "dist_norm = BoundaryNorm(dist_levels, dist_cmap.N, clip=True)\n",
    "\n",
    "im = ax.imshow(distance_km, cmap=dist_cmap, norm=dist_norm,\n",
    "               extent=extent, origin='upper',\n",
    "               interpolation='bilinear', aspect='equal', zorder=2)\n",
    "\n",
    "uk_boundary.boundary.plot(ax=ax, color='black', linewidth=1.5, zorder=10)\n",
    "\n",
    "if len(roads_sample) > 0:\n",
    "    roads_sample.plot(ax=ax, color='red', linewidth=0.3, alpha=0.5, zorder=11)\n",
    "\n",
    "ax.set_xlabel('Easting (m)', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Northing (m)', fontsize=14, fontweight='bold')\n",
    "ax.set_title('Distance to Nearest Major Road\\n(Transport Accessibility for Wind Farm Development)',\n",
    "             fontsize=18, fontweight='bold', pad=20)\n",
    "ax.ticklabel_format(style='plain')\n",
    "ax.tick_params(labelsize=11)\n",
    "\n",
    "cbar = plt.colorbar(im, ax=ax, pad=0.02, fraction=0.046,\n",
    "                    ticks=[0, 5, 10, 15, 20, 25, 30])\n",
    "cbar.set_label('Distance (km)', fontsize=13, fontweight='bold')\n",
    "cbar.ax.tick_params(labelsize=11)\n",
    "\n",
    "valid_dist = distance_km[~np.isnan(distance_km)]\n",
    "d_pct = [\n",
    "    ((valid_dist<2).sum()/len(valid_dist)*100),\n",
    "    (((valid_dist>=2)&(valid_dist<5)).sum()/len(valid_dist)*100),\n",
    "    (((valid_dist>=5)&(valid_dist<10)).sum()/len(valid_dist)*100),\n",
    "    (((valid_dist>=10)&(valid_dist<15)).sum()/len(valid_dist)*100),\n",
    "    ((valid_dist>=15).sum()/len(valid_dist)*100)\n",
    "]\n",
    "\n",
    "legend_elements = [\n",
    "    mpatches.Patch(color='#313695', label=f'Very close (<2 km): {d_pct[0]:.1f}%'),\n",
    "    mpatches.Patch(color='#74add1', label=f'Optimal (2-5 km): {d_pct[1]:.1f}%'),\n",
    "    mpatches.Patch(color='#ffffbf', label=f'Good (5-10 km): {d_pct[2]:.1f}%'),\n",
    "    mpatches.Patch(color='#fdae61', label=f'Moderate (10-15 km): {d_pct[3]:.1f}%'),\n",
    "    mpatches.Patch(color='#d73027', label=f'Far (>15 km): {d_pct[4]:.1f}%'),\n",
    "]\n",
    "\n",
    "legend = ax.legend(handles=legend_elements, loc='upper left',\n",
    "                   fontsize=10, framealpha=0.95, edgecolor='black',\n",
    "                   title='Distance Classification', title_fontsize=11,\n",
    "                   fancybox=True, shadow=True)\n",
    "legend.get_frame().set_linewidth(1.5)\n",
    "\n",
    "stats_text = f\"\"\"Statistics (Distance):\n",
    "Mean: {valid_dist.mean():.1f} km\n",
    "Min: {valid_dist.min():.1f} km\n",
    "Max: {valid_dist.max():.1f} km\n",
    "Median: {np.median(valid_dist):.1f} km\n",
    "Std: {valid_dist.std():.1f} km\n",
    "\n",
    "Accessible (<=15 km):\n",
    "{(valid_dist <= 15).sum() / len(valid_dist) * 100:.1f}%\n",
    "\n",
    "Roads Included:\n",
    "Motorways, trunk,\n",
    "primary, Major Road\n",
    "\n",
    "Total: {len(roads_clipped):,} segments\n",
    "Length: {roads_clipped.geometry.length.sum()/1000:.0f} km\n",
    "\n",
    "Grid: {rows}x{cols}\n",
    "Coverage: {len(valid_dist):,} cells\n",
    "({len(valid_dist)/(rows*cols)*100:.1f}%)\"\"\"\n",
    "\n",
    "props = dict(boxstyle='round', facecolor='white', alpha=0.95,\n",
    "             edgecolor='black', linewidth=1.5)\n",
    "ax.text(0.02, 0.15, stats_text, transform=ax.transAxes,\n",
    "        fontsize=9, verticalalignment='bottom', horizontalalignment='left',\n",
    "        bbox=props, fontfamily='monospace')\n",
    "\n",
    "scale_x = extent[0] + (extent[1] - extent[0]) * 0.05\n",
    "scale_y = extent[2] + (extent[3] - extent[2]) * 0.05\n",
    "scale_length = 100000\n",
    "\n",
    "ax.plot([scale_x, scale_x + scale_length], [scale_y, scale_y], 'k-', linewidth=3, zorder=15)\n",
    "ax.plot([scale_x, scale_x], [scale_y - 5000, scale_y + 5000], 'k-', linewidth=3, zorder=15)\n",
    "ax.plot([scale_x + scale_length, scale_x + scale_length],\n",
    "        [scale_y - 5000, scale_y + 5000], 'k-', linewidth=3, zorder=15)\n",
    "ax.text(scale_x + scale_length/2, scale_y + 12000, '100 km',\n",
    "        ha='center', fontsize=11, fontweight='bold',\n",
    "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.9), zorder=15)\n",
    "\n",
    "arrow_x = extent[1] - (extent[1] - extent[0]) * 0.05\n",
    "arrow_y = extent[3] - (extent[3] - extent[2]) * 0.08\n",
    "ax.annotate('N', xy=(arrow_x, arrow_y + 40000), xytext=(arrow_x, arrow_y),\n",
    "            arrowprops=dict(arrowstyle='->', lw=3, color='black'),\n",
    "            fontsize=16, fontweight='bold', ha='center', zorder=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(MAP1_FILE, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "print(f\"Saved: {MAP1_FILE}\")\n",
    "plt.close()\n",
    "\n",
    "# Map 2: Suitability Score\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MAP 2: Road Proximity Suitability Score\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 18), dpi=300)\n",
    "ax.set_facecolor('#e6f2ff')\n",
    "ax.grid(True, alpha=0.3, linestyle='--', linewidth=0.5, color='gray', zorder=1)\n",
    "\n",
    "score_colors = [\n",
    "    '#d73027', '#f46d43', '#fdae61', '#fee090', '#ffffbf',\n",
    "    '#d9ef8b', '#a6d96a', '#66bd63', '#1a9850', '#006837'\n",
    "]\n",
    "score_cmap = LinearSegmentedColormap.from_list('score', score_colors, N=256)\n",
    "score_levels = np.arange(0, 10.5, 0.5)\n",
    "score_norm = BoundaryNorm(score_levels, score_cmap.N, clip=True)\n",
    "\n",
    "im = ax.imshow(score_data, cmap=score_cmap, norm=score_norm,\n",
    "               extent=extent, origin='upper',\n",
    "               interpolation='bilinear', aspect='equal', zorder=2)\n",
    "\n",
    "uk_boundary.boundary.plot(ax=ax, color='black', linewidth=1.5, zorder=10)\n",
    "\n",
    "if len(roads_sample) > 0:\n",
    "    roads_sample.plot(ax=ax, color='darkred', linewidth=0.3, alpha=0.5, zorder=11)\n",
    "\n",
    "ax.set_xlabel('Easting (m)', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Northing (m)', fontsize=14, fontweight='bold')\n",
    "ax.set_title('Road Proximity Suitability Score (0-10)\\n(Based on Distance to Major Roads)',\n",
    "             fontsize=18, fontweight='bold', pad=20)\n",
    "ax.ticklabel_format(style='plain')\n",
    "ax.tick_params(labelsize=11)\n",
    "\n",
    "cbar = plt.colorbar(im, ax=ax, pad=0.02, fraction=0.046,\n",
    "                    ticks=[0, 2, 4, 6, 8, 10])\n",
    "cbar.set_label('Suitability Score', fontsize=13, fontweight='bold')\n",
    "cbar.ax.tick_params(labelsize=11)\n",
    "\n",
    "threshold_info = [\n",
    "    (0, '0 (D>15)', '#d73027'),\n",
    "    (3.33, '3.3 (D=12)', '#fdae61'),\n",
    "    (6.67, '6.7 (D=8)', '#a6d96a'),\n",
    "    (10, '10 (2-5km)', '#006837'),\n",
    "]\n",
    "\n",
    "for score, label, color in threshold_info:\n",
    "    cbar.ax.axhline(y=score, color=color, linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "    cbar.ax.text(1.3, score, label, fontsize=8, va='center',\n",
    "                 color=color, fontweight='bold',\n",
    "                 bbox=dict(boxstyle='round', facecolor='white', alpha=0.8,\n",
    "                          edgecolor=color, linewidth=1))\n",
    "\n",
    "valid_scores = score_data[~np.isnan(score_data)]\n",
    "s_pct = [\n",
    "    ((valid_scores>=9).sum()/len(valid_scores)*100),\n",
    "    (((valid_scores>=7)&(valid_scores<9)).sum()/len(valid_scores)*100),\n",
    "    (((valid_scores>=5)&(valid_scores<7)).sum()/len(valid_scores)*100),\n",
    "    (((valid_scores>=3)&(valid_scores<5)).sum()/len(valid_scores)*100),\n",
    "    (((valid_scores>0)&(valid_scores<3)).sum()/len(valid_scores)*100),\n",
    "    ((valid_scores==0).sum()/len(valid_scores)*100)\n",
    "]\n",
    "\n",
    "legend_elements = [\n",
    "    mpatches.Patch(color='#006837', label=f'Excellent (9-10): 2-5 km - {s_pct[0]:.1f}%'),\n",
    "    mpatches.Patch(color='#66bd63', label=f'Good (7-9): <2 or 6-8 km - {s_pct[1]:.1f}%'),\n",
    "    mpatches.Patch(color='#a6d96a', label=f'Fair (5-7): 8-10 km - {s_pct[2]:.1f}%'),\n",
    "    mpatches.Patch(color='#ffffbf', label=f'Marginal (3-5): 10-12 km - {s_pct[3]:.1f}%'),\n",
    "    mpatches.Patch(color='#fdae61', label=f'Poor (1-3): 12-14 km - {s_pct[4]:.1f}%'),\n",
    "    mpatches.Patch(color='#d73027', label=f'Unsuitable (0): >15 km - {s_pct[5]:.1f}%'),\n",
    "]\n",
    "\n",
    "legend = ax.legend(handles=legend_elements, loc='upper left',\n",
    "                   fontsize=10, framealpha=0.95, edgecolor='black',\n",
    "                   title='Suitability Classes', title_fontsize=11,\n",
    "                   fancybox=True, shadow=True)\n",
    "legend.get_frame().set_linewidth(1.5)\n",
    "\n",
    "score_dist = [\n",
    "    (0, 0.01, 'Zero'),\n",
    "    (0.01, 3, 'Low'),\n",
    "    (3, 6, 'Medium'),\n",
    "    (6, 9, 'High'),\n",
    "    (9, 10.01, 'V.High'),\n",
    "]\n",
    "\n",
    "dist_text = \"Distribution:\\n\"\n",
    "for s_min, s_max, label in score_dist:\n",
    "    mask = (valid_scores >= s_min) & (valid_scores < s_max)\n",
    "    pct = mask.sum() / len(valid_scores) * 100\n",
    "    dist_text += f\"{label:>7s}: {pct:5.1f}%\\n\"\n",
    "\n",
    "stats_text = f\"\"\"Statistics (Score):\n",
    "Mean: {valid_scores.mean():.2f}\n",
    "Min: {valid_scores.min():.2f}\n",
    "Max: {valid_scores.max():.2f}\n",
    "Median: {np.median(valid_scores):.2f}\n",
    "Std: {valid_scores.std():.2f}\n",
    "\n",
    "{dist_text}\n",
    "Scoring Formula:\n",
    "D<2km: s=8\n",
    "2<=D<=5km: s=10\n",
    "5<D<=15km: s=15-D\n",
    "D>15km: s=0\n",
    "\n",
    "WLC Weight: 8.2%\n",
    "\n",
    "Grid: {rows}x{cols}\n",
    "Coverage: {len(valid_scores):,} cells\"\"\"\n",
    "\n",
    "props = dict(boxstyle='round', facecolor='white', alpha=0.95,\n",
    "             edgecolor='black', linewidth=1.5)\n",
    "ax.text(0.02, 0.15, stats_text, transform=ax.transAxes,\n",
    "        fontsize=8.5, verticalalignment='bottom', horizontalalignment='left',\n",
    "        bbox=props, fontfamily='monospace')\n",
    "\n",
    "ax.plot([scale_x, scale_x + scale_length], [scale_y, scale_y], 'k-', linewidth=3, zorder=15)\n",
    "ax.plot([scale_x, scale_x], [scale_y - 5000, scale_y + 5000], 'k-', linewidth=3, zorder=15)\n",
    "ax.plot([scale_x + scale_length, scale_x + scale_length],\n",
    "        [scale_y - 5000, scale_y + 5000], 'k-', linewidth=3, zorder=15)\n",
    "ax.text(scale_x + scale_length/2, scale_y + 12000, '100 km',\n",
    "        ha='center', fontsize=11, fontweight='bold',\n",
    "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.9), zorder=15)\n",
    "\n",
    "ax.annotate('N', xy=(arrow_x, arrow_y + 40000), xytext=(arrow_x, arrow_y),\n",
    "            arrowprops=dict(arrowstyle='->', lw=3, color='black'),\n",
    "            fontsize=16, fontweight='bold', ha='center', zorder=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(MAP2_FILE, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "print(f\"Saved: {MAP2_FILE}\")\n",
    "plt.close()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VISUALIZATION COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Output files:\")\n",
    "print(f\"  {MAP1_FILE}\")\n",
    "print(f\"  {MAP2_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f37bc8-3f9b-4d7e-83c3-6058faf9c7dd",
   "metadata": {},
   "source": [
    "Slope Processing\n",
    "Calculates slope from terrain DEM and suitability scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed1bf7cd-b5f7-48f0-8851-cd248fdd9991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SLOPE PROCESSING\n",
      "================================================================================\n",
      "\n",
      "Step 1: Loading reference grid\n",
      "Target shape: 235 x 131\n",
      "Target pixel size: 5000 x 5000 m\n",
      "\n",
      "Step 2: Loading terrain and calculating slope\n",
      "Native shape: (492, 264)\n",
      "Native pixel size: 2500m\n",
      "Calculating slope at native resolution\n",
      "Native slope: 0.00 - 13.73 deg (mean: 0.39)\n",
      "\n",
      "Step 3: Resampling from 2500m to 5000m\n",
      "Resampled to 235 x 131\n",
      "Slope range: 0.00 - 8.79 deg (mean: 0.41)\n",
      "\n",
      "Slope distribution:\n",
      "  Flat (<=1 deg)           :  85.3%\n",
      "  Gentle (1-3 deg)         :  11.8%\n",
      "  Moderate (3-6 deg)       :   2.8%\n",
      "  Steep (6-10 deg)         :   0.1%\n",
      "  Very steep (>10 deg)     :   0.0%\n",
      "\n",
      "Step 4: Applying land mask\n",
      "Valid land cells: 10,397 (33.8%)\n",
      "\n",
      "Step 5: Calculating suitability scores\n",
      "Formula:\n",
      "  S <= 1 deg:    score = 10\n",
      "  1 < S <= 6 deg: score = 10 - 2(S-1)\n",
      "  S > 6 deg:     score = 0\n",
      "S <= 1 deg (score=10): 5,907 cells\n",
      "1 < S <= 6 deg (varies): 4,463 cells\n",
      "S > 6 deg (score=0): 27 cells\n",
      "\n",
      "Score statistics:\n",
      "  Mean: 8.98\n",
      "  Median: 10.00\n",
      "  Min: 0.00\n",
      "  Max: 10.00\n",
      "\n",
      "Score distribution:\n",
      "  Excellent (9-10): <=1 deg     :  71.4%\n",
      "  Good (7-9): 1-2 deg           :  15.9%\n",
      "  Fair (5-7): 2-3.5 deg         :   6.9%\n",
      "  Marginal (3-5): 3.5-5 deg     :   3.7%\n",
      "  Poor (1-3): 5-6 deg           :   1.5%\n",
      "  Unsuitable (0-1): >6 deg      :   0.6%\n",
      "\n",
      "Step 6: Saving GeoTIFF files\n",
      "Saved: D:\\BENV0093\\outputs\\slope_degrees.tif\n",
      "Saved: D:\\BENV0093\\outputs\\slope_suitability_score.tif\n",
      "\n",
      "Step 7: Verifying alignment with wind TIF\n",
      "  Shape: MATCH\n",
      "  CRS: MATCH\n",
      "  Transform: MATCH\n",
      "\n",
      "PERFECT ALIGNMENT\n",
      "\n",
      "================================================================================\n",
      "PROCESSING COMPLETE\n",
      "================================================================================\n",
      "Slope: 0.00 - 8.79 deg (mean: 0.41)\n",
      "Score: 0.00 - 10.00 (mean: 8.98)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.transform import Affine\n",
    "from rasterio.enums import Resampling\n",
    "import rasterio.warp\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SLOPE PROCESSING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "BASE_DIR = Path('D:/BENV0093')\n",
    "DATASET_DIR = BASE_DIR / 'Dateset_T2'\n",
    "OUTPUT_DIR = BASE_DIR / 'outputs'\n",
    "\n",
    "TERRAIN_TIF = DATASET_DIR / 'Terrain' / 'terrain.tif'\n",
    "REFERENCE_GRID_PKL = OUTPUT_DIR / 'reference_grid.pkl'\n",
    "WIND_TIF = OUTPUT_DIR / 'wind_suitability_score_original.tif'\n",
    "\n",
    "SLOPE_TIF = OUTPUT_DIR / 'slope_degrees.tif'\n",
    "SLOPE_SCORE_TIF = OUTPUT_DIR / 'slope_suitability_score.tif'\n",
    "\n",
    "SLOPE_EXCELLENT = 1\n",
    "SLOPE_MAX = 6\n",
    "NODATA_VALUE = -9999\n",
    "CRS_EPSG = 27700\n",
    "\n",
    "if not TERRAIN_TIF.exists():\n",
    "    print(f\"ERROR: Terrain file not found: {TERRAIN_TIF}\")\n",
    "    exit(1)\n",
    "\n",
    "# Step 1: Load reference grid\n",
    "print(\"\\nStep 1: Loading reference grid\")\n",
    "with open(REFERENCE_GRID_PKL, 'rb') as f:\n",
    "    ref = pickle.load(f)\n",
    "\n",
    "target_rows, target_cols = ref['shape']\n",
    "target_pixel_size = ref['pixel_size']\n",
    "target_extent = ref['extent']\n",
    "\n",
    "target_transform = Affine(\n",
    "    target_pixel_size[0], 0, target_extent[0],\n",
    "    0, -abs(target_pixel_size[1]), target_extent[3]\n",
    ")\n",
    "\n",
    "print(f\"Target shape: {target_rows} x {target_cols}\")\n",
    "print(f\"Target pixel size: {target_pixel_size[0]:.0f} x {abs(target_pixel_size[1]):.0f} m\")\n",
    "\n",
    "# Step 2: Load terrain and calculate slope at native resolution\n",
    "print(\"\\nStep 2: Loading terrain and calculating slope\")\n",
    "with rasterio.open(TERRAIN_TIF) as src:\n",
    "    elevation_native = src.read(1).astype('float32')\n",
    "    native_transform = src.transform\n",
    "    native_pixel_size = abs(native_transform.a)\n",
    "    native_crs = src.crs\n",
    "    \n",
    "    print(f\"Native shape: {elevation_native.shape}\")\n",
    "    print(f\"Native pixel size: {native_pixel_size:.0f}m\")\n",
    "    \n",
    "    elevation_nodata = src.nodata\n",
    "    if elevation_nodata is not None:\n",
    "        elevation_native[elevation_native == elevation_nodata] = np.nan\n",
    "    \n",
    "    elevation_native[elevation_native < -1000] = np.nan\n",
    "    elevation_native[elevation_native > 2000] = np.nan\n",
    "\n",
    "print(\"Calculating slope at native resolution\")\n",
    "dy_native, dx_native = np.gradient(elevation_native)\n",
    "\n",
    "dy_per_meter = dy_native / native_pixel_size\n",
    "dx_per_meter = dx_native / native_pixel_size\n",
    "\n",
    "slope_radians_native = np.arctan(np.sqrt(dx_per_meter**2 + dy_per_meter**2))\n",
    "slope_degrees_native = np.degrees(slope_radians_native)\n",
    "\n",
    "slope_degrees_native[np.isnan(elevation_native)] = np.nan\n",
    "\n",
    "valid_slope_native = slope_degrees_native[~np.isnan(slope_degrees_native)]\n",
    "print(f\"Native slope: {valid_slope_native.min():.2f} - {valid_slope_native.max():.2f} deg (mean: {valid_slope_native.mean():.2f})\")\n",
    "\n",
    "# Step 3: Resample slope to target grid\n",
    "print(f\"\\nStep 3: Resampling from {native_pixel_size:.0f}m to {target_pixel_size[0]:.0f}m\")\n",
    "slope_degrees = np.empty((target_rows, target_cols), dtype=np.float32)\n",
    "\n",
    "rasterio.warp.reproject(\n",
    "    source=slope_degrees_native,\n",
    "    destination=slope_degrees,\n",
    "    src_transform=native_transform,\n",
    "    src_crs=native_crs,\n",
    "    dst_transform=target_transform,\n",
    "    dst_crs=f'EPSG:{CRS_EPSG}',\n",
    "    resampling=Resampling.average\n",
    ")\n",
    "\n",
    "print(f\"Resampled to {target_rows} x {target_cols}\")\n",
    "\n",
    "valid_slope = slope_degrees[~np.isnan(slope_degrees)]\n",
    "print(f\"Slope range: {valid_slope.min():.2f} - {valid_slope.max():.2f} deg (mean: {valid_slope.mean():.2f})\")\n",
    "\n",
    "slope_ranges = [\n",
    "    (0, 1, \"Flat (<=1 deg)\"),\n",
    "    (1, 3, \"Gentle (1-3 deg)\"),\n",
    "    (3, 6, \"Moderate (3-6 deg)\"),\n",
    "    (6, 10, \"Steep (6-10 deg)\"),\n",
    "    (10, np.inf, \"Very steep (>10 deg)\"),\n",
    "]\n",
    "\n",
    "print(\"\\nSlope distribution:\")\n",
    "for s_min, s_max, label in slope_ranges:\n",
    "    mask = (valid_slope >= s_min) & (valid_slope < s_max)\n",
    "    pct = mask.sum() / len(valid_slope) * 100\n",
    "    print(f\"  {label:25s}: {pct:5.1f}%\")\n",
    "\n",
    "# Step 4: Apply land mask\n",
    "print(\"\\nStep 4: Applying land mask\")\n",
    "with rasterio.open(WIND_TIF) as src:\n",
    "    wind_data = src.read(1)\n",
    "    land_mask = (wind_data != NODATA_VALUE) & (~np.isnan(wind_data))\n",
    "\n",
    "slope_degrees[~land_mask] = np.nan\n",
    "\n",
    "valid_land_cells = land_mask.sum()\n",
    "print(f\"Valid land cells: {valid_land_cells:,} ({valid_land_cells/(target_rows*target_cols)*100:.1f}%)\")\n",
    "\n",
    "# Step 5: Calculate suitability scores\n",
    "print(\"\\nStep 5: Calculating suitability scores\")\n",
    "print(f\"Formula:\")\n",
    "print(f\"  S <= 1 deg:    score = 10\")\n",
    "print(f\"  1 < S <= 6 deg: score = 10 - 2(S-1)\")\n",
    "print(f\"  S > 6 deg:     score = 0\")\n",
    "\n",
    "suitability_score = np.zeros_like(slope_degrees, dtype='float32')\n",
    "\n",
    "mask1 = slope_degrees <= SLOPE_EXCELLENT\n",
    "suitability_score[mask1] = 10\n",
    "\n",
    "mask2 = (slope_degrees > SLOPE_EXCELLENT) & (slope_degrees <= SLOPE_MAX)\n",
    "suitability_score[mask2] = 10 - (10 / (SLOPE_MAX - SLOPE_EXCELLENT)) * (slope_degrees[mask2] - SLOPE_EXCELLENT)\n",
    "\n",
    "suitability_score[~land_mask] = np.nan\n",
    "\n",
    "print(f\"S <= {SLOPE_EXCELLENT} deg (score=10): {mask1.sum():,} cells\")\n",
    "print(f\"{SLOPE_EXCELLENT} < S <= {SLOPE_MAX} deg (varies): {mask2.sum():,} cells\")\n",
    "print(f\"S > {SLOPE_MAX} deg (score=0): {((slope_degrees > SLOPE_MAX) & land_mask).sum():,} cells\")\n",
    "\n",
    "valid_scores = suitability_score[~np.isnan(suitability_score)]\n",
    "print(f\"\\nScore statistics:\")\n",
    "print(f\"  Mean: {valid_scores.mean():.2f}\")\n",
    "print(f\"  Median: {np.median(valid_scores):.2f}\")\n",
    "print(f\"  Min: {valid_scores.min():.2f}\")\n",
    "print(f\"  Max: {valid_scores.max():.2f}\")\n",
    "\n",
    "score_ranges = [\n",
    "    (9, 10.01, \"Excellent (9-10): <=1 deg\"),\n",
    "    (7, 9, \"Good (7-9): 1-2 deg\"),\n",
    "    (5, 7, \"Fair (5-7): 2-3.5 deg\"),\n",
    "    (3, 5, \"Marginal (3-5): 3.5-5 deg\"),\n",
    "    (1, 3, \"Poor (1-3): 5-6 deg\"),\n",
    "    (0, 1, \"Unsuitable (0-1): >6 deg\"),\n",
    "]\n",
    "\n",
    "print(\"\\nScore distribution:\")\n",
    "for s_min, s_max, label in score_ranges:\n",
    "    mask = (valid_scores >= s_min) & (valid_scores < s_max)\n",
    "    pct = mask.sum() / len(valid_scores) * 100\n",
    "    print(f\"  {label:30s}: {pct:5.1f}%\")\n",
    "\n",
    "# Step 6: Save GeoTIFF files\n",
    "print(\"\\nStep 6: Saving GeoTIFF files\")\n",
    "metadata = {\n",
    "    'driver': 'GTiff',\n",
    "    'dtype': 'float32',\n",
    "    'nodata': NODATA_VALUE,\n",
    "    'width': target_cols,\n",
    "    'height': target_rows,\n",
    "    'count': 1,\n",
    "    'crs': f'EPSG:{CRS_EPSG}',\n",
    "    'transform': target_transform,\n",
    "    'compress': 'lzw'\n",
    "}\n",
    "\n",
    "slope_save = np.where(np.isnan(slope_degrees), NODATA_VALUE, slope_degrees)\n",
    "with rasterio.open(SLOPE_TIF, 'w', **metadata) as dst:\n",
    "    dst.write(slope_save.astype('float32'), 1)\n",
    "print(f\"Saved: {SLOPE_TIF}\")\n",
    "\n",
    "score_save = np.where(np.isnan(suitability_score), NODATA_VALUE, suitability_score)\n",
    "with rasterio.open(SLOPE_SCORE_TIF, 'w', **metadata) as dst:\n",
    "    dst.write(score_save.astype('float32'), 1)\n",
    "print(f\"Saved: {SLOPE_SCORE_TIF}\")\n",
    "\n",
    "# Step 7: Verify alignment\n",
    "print(\"\\nStep 7: Verifying alignment with wind TIF\")\n",
    "with rasterio.open(WIND_TIF) as wind, rasterio.open(SLOPE_SCORE_TIF) as slope:\n",
    "    checks = {\n",
    "        'Shape': wind.shape == slope.shape,\n",
    "        'CRS': wind.crs == slope.crs,\n",
    "        'Transform': wind.transform.almost_equals(slope.transform, precision=0.01),\n",
    "    }\n",
    "    \n",
    "    for check, result in checks.items():\n",
    "        status = \"MATCH\" if result else \"MISMATCH\"\n",
    "        print(f\"  {check}: {status}\")\n",
    "    \n",
    "    if all(checks.values()):\n",
    "        print(\"\\nPERFECT ALIGNMENT\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PROCESSING COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Slope: {valid_slope.min():.2f} - {valid_slope.max():.2f} deg (mean: {valid_slope.mean():.2f})\")\n",
    "print(f\"Score: {valid_scores.min():.2f} - {valid_scores.max():.2f} (mean: {valid_scores.mean():.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125a7c98-f5c3-4e37-8c3d-8fa862f7085c",
   "metadata": {},
   "source": [
    "Slope Visualization\n",
    "Generates maps for slope and suitability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33a62ee4-68d1-4aa1-8bdc-3deee97da1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SLOPE VISUALIZATION (FIXED)\n",
      "================================================================================\n",
      "\n",
      "Loading reference grid\n",
      "Shape: 235 x 131\n",
      "Extent: X[0, 655000], Y[10000, 1185000]\n",
      "\n",
      "Loading raster data\n",
      "Loading UK boundary\n",
      "Valid slope cells: 10,397\n",
      "Valid score cells: 10,397\n",
      "\n",
      "Slope statistics:\n",
      "  Min: 0.00°\n",
      "  Max: 8.79°\n",
      "  Mean: 1.19°\n",
      "  Median: 0.82°\n",
      "\n",
      "Slope distribution:\n",
      "  ≤ 1°:   5,907 cells ( 56.8%)\n",
      "  ≤ 2°:   8,399 cells ( 80.8%)\n",
      "  ≤ 3°:   9,508 cells ( 91.4%)\n",
      "  ≤ 6°:  10,370 cells ( 99.7%)\n",
      "  ≤10°:  10,397 cells (100.0%)\n",
      "  ≤15°:  10,397 cells (100.0%)\n",
      "\n",
      "================================================================================\n",
      "MAP 1: Slope (Degrees)\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\888\\AppData\\Local\\Temp\\ipykernel_31336\\1025099571.py:119: UserWarning: Setting the 'color' property will override the edgecolor or facecolor properties.\n",
      "  mpatches.Patch(color='#ffffff',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total percentage check: 100.0% (should be ~100%)\n",
      "✓ Saved: D:\\BENV0093\\outputs\\map7_slope_degrees.png\n",
      "\n",
      "================================================================================\n",
      "MAP 2: Slope Suitability Score\n",
      "================================================================================\n",
      "✓ Saved: D:\\BENV0093\\outputs\\map8_slope_suitability_score.png\n",
      "\n",
      "================================================================================\n",
      "VISUALIZATION COMPLETE\n",
      "================================================================================\n",
      "\n",
      "Key fixes:\n",
      "  1. Legend categories now cover full data range (0-10+°)\n",
      "  2. Percentages sum to 100%: 100.0%\n",
      "  3. Colorbar range adjusted to show actual data distribution\n",
      "  4. WLC weight updated to 6.5%\n",
      "\n",
      "Output files:\n",
      "  D:\\BENV0093\\outputs\\map7_slope_degrees.png\n",
      "  D:\\BENV0093\\outputs\\map8_slope_suitability_score.png\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.patches as mpatches\n",
    "import geopandas as gpd\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SLOPE VISUALIZATION (FIXED)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "BASE_DIR = Path('D:/BENV0093')\n",
    "OUTPUT_DIR = BASE_DIR / 'outputs'\n",
    "\n",
    "SLOPE_TIF = OUTPUT_DIR / 'slope_degrees.tif'\n",
    "SLOPE_SCORE_TIF = OUTPUT_DIR / 'slope_suitability_score.tif'\n",
    "UK_BOUNDARY_SHP = BASE_DIR / 'UK_ITL1_Boundaries.shp'\n",
    "REFERENCE_GRID_PKL = OUTPUT_DIR / 'reference_grid.pkl'\n",
    "\n",
    "MAP1_FILE = OUTPUT_DIR / 'map7_slope_degrees.png'\n",
    "MAP2_FILE = OUTPUT_DIR / 'map8_slope_suitability_score.png'\n",
    "\n",
    "NODATA_VALUE = -9999\n",
    "CRS_EPSG = 27700\n",
    "\n",
    "# Load reference grid\n",
    "print(\"\\nLoading reference grid\")\n",
    "with open(REFERENCE_GRID_PKL, 'rb') as f:\n",
    "    ref_grid = pickle.load(f)\n",
    "\n",
    "rows, cols = ref_grid['shape']\n",
    "extent = ref_grid['extent']\n",
    "\n",
    "print(f\"Shape: {rows} x {cols}\")\n",
    "print(f\"Extent: X[{extent[0]:.0f}, {extent[1]:.0f}], Y[{extent[2]:.0f}, {extent[3]:.0f}]\")\n",
    "\n",
    "# Load rasters\n",
    "print(\"\\nLoading raster data\")\n",
    "with rasterio.open(SLOPE_TIF) as src:\n",
    "    slope_degrees = src.read(1)\n",
    "    slope_degrees[slope_degrees == NODATA_VALUE] = np.nan\n",
    "\n",
    "with rasterio.open(SLOPE_SCORE_TIF) as src:\n",
    "    suitability_score = src.read(1)\n",
    "    suitability_score[suitability_score == NODATA_VALUE] = np.nan\n",
    "\n",
    "# Load UK boundary\n",
    "print(\"Loading UK boundary\")\n",
    "uk_boundary = gpd.read_file(UK_BOUNDARY_SHP)\n",
    "if uk_boundary.crs.to_epsg() != CRS_EPSG:\n",
    "    uk_boundary = uk_boundary.to_crs(f'EPSG:{CRS_EPSG}')\n",
    "\n",
    "valid_slope = slope_degrees[~np.isnan(slope_degrees)]\n",
    "valid_scores = suitability_score[~np.isnan(suitability_score)]\n",
    "\n",
    "print(f\"Valid slope cells: {len(valid_slope):,}\")\n",
    "print(f\"Valid score cells: {len(valid_scores):,}\")\n",
    "\n",
    "# Statistics\n",
    "print(f\"\\nSlope statistics:\")\n",
    "print(f\"  Min: {valid_slope.min():.2f}°\")\n",
    "print(f\"  Max: {valid_slope.max():.2f}°\")\n",
    "print(f\"  Mean: {valid_slope.mean():.2f}°\")\n",
    "print(f\"  Median: {np.median(valid_slope):.2f}°\")\n",
    "\n",
    "# Distribution analysis\n",
    "print(f\"\\nSlope distribution:\")\n",
    "for threshold in [1, 2, 3, 6, 10, 15]:\n",
    "    count = (valid_slope <= threshold).sum()\n",
    "    pct = count / len(valid_slope) * 100\n",
    "    print(f\"  ≤{threshold:2d}°: {count:7,} cells ({pct:5.1f}%)\")\n",
    "\n",
    "# Map 1: Slope in degrees\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MAP 1: Slope (Degrees)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 18), dpi=300)\n",
    "ax.set_facecolor('#e6f2ff')\n",
    "ax.grid(True, alpha=0.3, linestyle='--', linewidth=0.5, color='gray', zorder=1)\n",
    "\n",
    "# Colormap for 0-6 degrees (matches vmax)\n",
    "slope_colors = [\n",
    "    '#ffffff', '#ffffcc', '#ffeda0', '#fed976', '#feb24c', '#fd8d3c', '#fc4e2a', '#e31a1c', '#bd0026'\n",
    "]\n",
    "slope_cmap = LinearSegmentedColormap.from_list('slope', slope_colors, N=256)\n",
    "\n",
    "# Cap display at reasonable maximum\n",
    "vmax_display = min(15, np.percentile(valid_slope, 99))  # Use 99th percentile or 15°\n",
    "\n",
    "im = ax.imshow(slope_degrees, cmap=slope_cmap,\n",
    "               extent=extent, origin='upper',\n",
    "               vmin=0, vmax=vmax_display,\n",
    "               interpolation='bilinear', zorder=2)\n",
    "\n",
    "uk_boundary.boundary.plot(ax=ax, color='black', linewidth=1.5, zorder=10)\n",
    "\n",
    "ax.set_xlabel('Easting (m)', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Northing (m)', fontsize=14, fontweight='bold')\n",
    "ax.set_title('Terrain Slope (Degrees)\\n(Wind Farm Development Constraint)',\n",
    "             fontsize=18, fontweight='bold', pad=20)\n",
    "ax.ticklabel_format(style='plain')\n",
    "ax.tick_params(labelsize=11)\n",
    "\n",
    "cbar = plt.colorbar(im, ax=ax, pad=0.02, fraction=0.046, shrink=0.8)\n",
    "cbar.set_label('Slope (degrees)', fontsize=13, fontweight='bold', labelpad=10)\n",
    "cbar.ax.tick_params(labelsize=10)\n",
    "\n",
    "# Add threshold lines\n",
    "cbar.ax.axhline(y=1, color='lime', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "cbar.ax.text(1.35, 1, '1°', fontsize=8, va='center')\n",
    "cbar.ax.axhline(y=6, color='red', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "cbar.ax.text(1.35, 6, '6°', fontsize=8, va='center')\n",
    "\n",
    "# FIXED: Legend categories that match the actual data range and sum to 100%\n",
    "legend_elements = [\n",
    "    mpatches.Patch(color='#ffffff', \n",
    "                   label=f'Flat (0-1°): {((valid_slope <= 1).sum()/len(valid_slope)*100):.1f}%', \n",
    "                   edgecolor='gray'),\n",
    "    mpatches.Patch(color='#ffeda0', \n",
    "                   label=f'Gentle (1-2°): {(((valid_slope > 1) & (valid_slope <= 2)).sum()/len(valid_slope)*100):.1f}%'),\n",
    "    mpatches.Patch(color='#feb24c', \n",
    "                   label=f'Moderate (2-3°): {(((valid_slope > 2) & (valid_slope <= 3)).sum()/len(valid_slope)*100):.1f}%'),\n",
    "    mpatches.Patch(color='#fd8d3c', \n",
    "                   label=f'Moderately Steep (3-6°): {(((valid_slope > 3) & (valid_slope <= 6)).sum()/len(valid_slope)*100):.1f}%'),\n",
    "    mpatches.Patch(color='#e31a1c', \n",
    "                   label=f'Steep (6-10°): {(((valid_slope > 6) & (valid_slope <= 10)).sum()/len(valid_slope)*100):.1f}%'),\n",
    "    mpatches.Patch(color='#bd0026', \n",
    "                   label=f'Very Steep (>10°): {((valid_slope > 10).sum()/len(valid_slope)*100):.1f}%'),\n",
    "]\n",
    "\n",
    "legend = ax.legend(handles=legend_elements, loc='upper left',\n",
    "                   fontsize=9, framealpha=0.95, edgecolor='black',\n",
    "                   title='Slope Classification', title_fontsize=10,\n",
    "                   fancybox=True, shadow=True)\n",
    "\n",
    "# Verify percentages sum to 100%\n",
    "total_pct = sum([\n",
    "    ((valid_slope <= 1).sum()/len(valid_slope)*100),\n",
    "    (((valid_slope > 1) & (valid_slope <= 2)).sum()/len(valid_slope)*100),\n",
    "    (((valid_slope > 2) & (valid_slope <= 3)).sum()/len(valid_slope)*100),\n",
    "    (((valid_slope > 3) & (valid_slope <= 6)).sum()/len(valid_slope)*100),\n",
    "    (((valid_slope > 6) & (valid_slope <= 10)).sum()/len(valid_slope)*100),\n",
    "    ((valid_slope > 10).sum()/len(valid_slope)*100)\n",
    "])\n",
    "print(f\"Total percentage check: {total_pct:.1f}% (should be ~100%)\")\n",
    "\n",
    "stats_text = f\"\"\"Slope Statistics (deg):\n",
    "Mean:   {valid_slope.mean():.2f}\n",
    "Median: {np.median(valid_slope):.2f}\n",
    "Std:    {valid_slope.std():.2f}\n",
    "Max:    {valid_slope.max():.2f}\n",
    "\n",
    "Coverage by slope:\n",
    "≤1°:   {((valid_slope <= 1).sum()/len(valid_slope)*100):.1f}%\n",
    "≤3°:   {((valid_slope <= 3).sum()/len(valid_slope)*100):.1f}%\n",
    "≤6°:   {((valid_slope <= 6).sum()/len(valid_slope)*100):.1f}%\n",
    ">6°:   {((valid_slope > 6).sum()/len(valid_slope)*100):.1f}%\n",
    "\n",
    "Thresholds:\n",
    "≤1°:  Excellent\n",
    "1-6°: Declining linearly\n",
    ">6°:  Unsuitable\n",
    "\n",
    "Grid: {rows}x{cols}\n",
    "Valid: {len(valid_slope):,} cells\"\"\"\n",
    "\n",
    "props = dict(boxstyle='round', facecolor='white', alpha=0.95,\n",
    "             edgecolor='black', linewidth=1.5)\n",
    "ax.text(0.02, 0.15, stats_text, transform=ax.transAxes,\n",
    "        fontsize=9, verticalalignment='bottom', bbox=props,\n",
    "        fontfamily='monospace')\n",
    "\n",
    "scale_x = extent[0] + (extent[1] - extent[0]) * 0.05\n",
    "scale_y = extent[2] + (extent[3] - extent[2]) * 0.05\n",
    "scale_length = 100000\n",
    "\n",
    "ax.plot([scale_x, scale_x + scale_length], [scale_y, scale_y], 'k-', linewidth=3, zorder=15)\n",
    "ax.plot([scale_x, scale_x], [scale_y - 5000, scale_y + 5000], 'k-', linewidth=3, zorder=15)\n",
    "ax.plot([scale_x + scale_length, scale_x + scale_length],\n",
    "        [scale_y - 5000, scale_y + 5000], 'k-', linewidth=3, zorder=15)\n",
    "ax.text(scale_x + scale_length/2, scale_y + 12000, '100 km',\n",
    "        ha='center', fontsize=11, fontweight='bold',\n",
    "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.9), zorder=15)\n",
    "\n",
    "arrow_x = extent[1] - (extent[1] - extent[0]) * 0.05\n",
    "arrow_y = extent[3] - (extent[3] - extent[2]) * 0.08\n",
    "ax.annotate('N', xy=(arrow_x, arrow_y + 40000), xytext=(arrow_x, arrow_y),\n",
    "            arrowprops=dict(arrowstyle='->', lw=3, color='black'),\n",
    "            fontsize=16, fontweight='bold', ha='center', zorder=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(MAP1_FILE, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "print(f\"✓ Saved: {MAP1_FILE}\")\n",
    "plt.close()\n",
    "\n",
    "# Map 2: Suitability Score\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MAP 2: Slope Suitability Score\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 18), dpi=300)\n",
    "ax.set_facecolor('#e6f2ff')\n",
    "ax.grid(True, alpha=0.3, linestyle='--', linewidth=0.5, color='gray', zorder=1)\n",
    "\n",
    "suit_colors = [\n",
    "    '#a50026', '#d73027', '#f46d43', '#fdae61', '#fee08b',\n",
    "    '#ffffbf', '#d9ef8b', '#a6d96a', '#66bd63', '#1a9850', '#006837'\n",
    "]\n",
    "suit_cmap = LinearSegmentedColormap.from_list('suitability_slope', suit_colors, N=256)\n",
    "\n",
    "im = ax.imshow(suitability_score, cmap=suit_cmap,\n",
    "               extent=extent, origin='upper',\n",
    "               vmin=0, vmax=10,\n",
    "               interpolation='bilinear', zorder=2)\n",
    "\n",
    "uk_boundary.boundary.plot(ax=ax, color='black', linewidth=1.5, zorder=10)\n",
    "\n",
    "ax.set_xlabel('Easting (m)', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Northing (m)', fontsize=14, fontweight='bold')\n",
    "ax.set_title('Slope Suitability Score (0-10)\\n(Based on Terrain Gradient)',\n",
    "             fontsize=18, fontweight='bold', pad=20)\n",
    "ax.ticklabel_format(style='plain')\n",
    "ax.tick_params(labelsize=11)\n",
    "\n",
    "cbar = plt.colorbar(im, ax=ax, pad=0.02, fraction=0.046, shrink=0.8)\n",
    "cbar.set_label('Suitability Score', fontsize=13, fontweight='bold', labelpad=10)\n",
    "cbar.ax.tick_params(labelsize=10)\n",
    "\n",
    "# Add score threshold lines\n",
    "for score in [5, 7, 9]:\n",
    "    cbar.ax.axhline(y=score, color='gray', linestyle=':', linewidth=1.5, alpha=0.5)\n",
    "\n",
    "# FIXED: Legend categories based on actual score distribution\n",
    "legend_elements = [\n",
    "    mpatches.Patch(color='#006837', \n",
    "                   label=f'Excellent (9-10): ≤1° - {((valid_scores >= 9).sum()/len(valid_scores)*100):.1f}%'),\n",
    "    mpatches.Patch(color='#66bd63', \n",
    "                   label=f'Good (7-9): 1-2° - {(((valid_scores >= 7) & (valid_scores < 9)).sum()/len(valid_scores)*100):.1f}%'),\n",
    "    mpatches.Patch(color='#d9ef8b', \n",
    "                   label=f'Fair (5-7): 2-3.5° - {(((valid_scores >= 5) & (valid_scores < 7)).sum()/len(valid_scores)*100):.1f}%'),\n",
    "    mpatches.Patch(color='#fdae61', \n",
    "                   label=f'Marginal (2-5): 3.5-5.5° - {(((valid_scores >= 2) & (valid_scores < 5)).sum()/len(valid_scores)*100):.1f}%'),\n",
    "    mpatches.Patch(color='#d73027', \n",
    "                   label=f'Poor (0-2): >5.5° - {(((valid_scores >= 0) & (valid_scores < 2)).sum()/len(valid_scores)*100):.1f}%'),\n",
    "]\n",
    "\n",
    "legend = ax.legend(handles=legend_elements, loc='upper left',\n",
    "                   fontsize=9, framealpha=0.95, edgecolor='black',\n",
    "                   title='Suitability Classes', title_fontsize=10,\n",
    "                   fancybox=True, shadow=True)\n",
    "\n",
    "stats_text = f\"\"\"Score Statistics:\n",
    "Mean:   {valid_scores.mean():.2f}\n",
    "Median: {np.median(valid_scores):.2f}\n",
    "Std:    {valid_scores.std():.2f}\n",
    "Min:    {valid_scores.min():.2f}\n",
    "Max:    {valid_scores.max():.2f}\n",
    "\n",
    "Scoring Formula:\n",
    "S ≤ 1°:      Score = 10\n",
    "1° < S ≤ 6°: Score = 10 - 2(S-1)\n",
    "S > 6°:      Score = 0\n",
    "\n",
    "Distribution:\n",
    "Excellent: {((valid_scores >= 9).sum()/len(valid_scores)*100):5.1f}%\n",
    "Good:      {(((valid_scores >= 7) & (valid_scores < 9)).sum()/len(valid_scores)*100):5.1f}%\n",
    "Fair:      {(((valid_scores >= 5) & (valid_scores < 7)).sum()/len(valid_scores)*100):5.1f}%\n",
    "Marginal:  {(((valid_scores >= 2) & (valid_scores < 5)).sum()/len(valid_scores)*100):5.1f}%\n",
    "Poor:      {((valid_scores < 2).sum()/len(valid_scores)*100):5.1f}%\n",
    "\n",
    "WLC Weight: 6.5%\n",
    "Grid: {rows}x{cols}\n",
    "Valid: {len(valid_scores):,} cells\"\"\"\n",
    "\n",
    "props = dict(boxstyle='round', facecolor='white', alpha=0.95,\n",
    "             edgecolor='black', linewidth=1.5)\n",
    "ax.text(0.02, 0.15, stats_text, transform=ax.transAxes,\n",
    "        fontsize=8.5, verticalalignment='bottom', bbox=props,\n",
    "        fontfamily='monospace')\n",
    "\n",
    "ax.plot([scale_x, scale_x + scale_length], [scale_y, scale_y], 'k-', linewidth=3, zorder=15)\n",
    "ax.plot([scale_x, scale_x], [scale_y - 5000, scale_y + 5000], 'k-', linewidth=3, zorder=15)\n",
    "ax.plot([scale_x + scale_length, scale_x + scale_length],\n",
    "        [scale_y - 5000, scale_y + 5000], 'k-', linewidth=3, zorder=15)\n",
    "ax.text(scale_x + scale_length/2, scale_y + 12000, '100 km',\n",
    "        ha='center', fontsize=11, fontweight='bold',\n",
    "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.9), zorder=15)\n",
    "\n",
    "ax.annotate('N', xy=(arrow_x, arrow_y + 40000), xytext=(arrow_x, arrow_y),\n",
    "            arrowprops=dict(arrowstyle='->', lw=3, color='black'),\n",
    "            fontsize=16, fontweight='bold', ha='center', zorder=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(MAP2_FILE, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "print(f\"✓ Saved: {MAP2_FILE}\")\n",
    "plt.close()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VISUALIZATION COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nKey fixes:\")\n",
    "print(f\"  1. Legend categories now cover full data range (0-10+°)\")\n",
    "print(f\"  2. Percentages sum to 100%: {total_pct:.1f}%\")\n",
    "print(f\"  3. Colorbar range adjusted to show actual data distribution\")\n",
    "print(f\"  4. WLC weight updated to 6.5%\")\n",
    "print(f\"\\nOutput files:\")\n",
    "print(f\"  {MAP1_FILE}\")\n",
    "print(f\"  {MAP2_FILE}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b4fc60-073b-457f-ae06-3db75c8deb10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
